{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "catholic-advisory",
   "metadata": {},
   "source": [
    "**Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "broken-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-robinson",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-sensitivity",
   "metadata": {},
   "source": [
    "**Nodes in each layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indian-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 1\n",
    "hidden_1_nodes = 2\n",
    "output_nodes = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-classics",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-advantage",
   "metadata": {},
   "source": [
    "**Inputs and true outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cathedral-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02333333],\n",
       "       [0.26333333],\n",
       "       [0.86      ],\n",
       "       [0.94666667],\n",
       "       [0.30333333],\n",
       "       [0.54      ],\n",
       "       [0.42333333],\n",
       "       [0.19      ],\n",
       "       [0.17666667],\n",
       "       [0.96666667]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.array([0.02333333, 0.26333333, 0.86, 0.94666667, 0.30333333, 0.54, 0.42333333, 0.19, 0.17666667, 0.96666667]).reshape((-1,1)) #np.random.randint(1, 100, size = (input_nodes, 1)) / 100\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continental-locking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [2],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.array([0, 0, 2, 2, 0, 1, 1, 0, 0, 2]).reshape((-1,1)) #np.array([[0],[1],[0]])\n",
    "ys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-philip",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-mills",
   "metadata": {},
   "source": [
    "**Defining Activation functions and loss with their derivatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-hunger",
   "metadata": {},
   "source": [
    "Sigmoid for first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compatible-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1 + np.exp(-x))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "western-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_dash(x):\n",
    "    return sig(x) * (1 - sig(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-affairs",
   "metadata": {},
   "source": [
    "Softmax for second hidden layer and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minor-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adjustable-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_dash(x):\n",
    "    \n",
    "    I = np.eye(x.shape[0])\n",
    "    sm = softmax(x)\n",
    "    smT = sm.T\n",
    "    IsmT = I - smT\n",
    "    \n",
    "    return sm * IsmT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-reference",
   "metadata": {},
   "source": [
    "Categorical cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7c876cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def targets_to_onehot(N_classes, targets):\n",
    "    one_hot = []\n",
    "    for value in range(len(targets)):\n",
    "        letter = [0 for _ in range(N_classes)]\n",
    "        letter[targets[value]] = 1\n",
    "        one_hot.append(letter)\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "synthetic-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_E(y_true, y_pred):\n",
    "    targets_one_hot = targets_to_onehot(len(y_pred), y_true)\n",
    "    eps = 1e-12\n",
    "    preds = np.clip(y_pred, eps, 1-eps)\n",
    "    N = preds.shape[0]\n",
    "    # return -np.sum(targets_one_hot*np.log(preds))/N\n",
    "    return -np.sum(targets_one_hot * np.log(y_pred + 10**-100))/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "macro-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_E_grad(y_true, y_pred):\n",
    "    return -y_true/(y_pred + 10**-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-willow",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-congo",
   "metadata": {},
   "source": [
    "**Random initialization of weights and biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adjacent-appraisal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.28401832]\n",
      " [-0.95381398]]\n",
      "[-0.52433746  0.3322185 ]\n"
     ]
    }
   ],
   "source": [
    "w1 = np.array([[0.28401832],[-0.95381398]]) #np.random.random(size = (hidden_1_nodes, input_nodes))\n",
    "b1 = np.array([-0.5243374610380842, 0.33221849539671044]) #np.zeros(shape = (hidden_1_nodes, 1))\n",
    "\n",
    "print(w1,b1, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vulnerable-interference",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.15495577 -0.56723879]\n",
      " [ 0.63793899 -0.37206676]\n",
      " [-0.71792529  0.49335413]]\n",
      "[0.3684357  0.90728299 0.52282658]\n"
     ]
    }
   ],
   "source": [
    "w2 = np.array([[-0.15495577, -0.56723879], [ 0.63793899, -0.37206676], [-0.71792529, 0.49335413]]) #np.random.random(size = (output_nodes, hidden_1_nodes))\n",
    "b2 = np.array([0.36843569825503186, 0.9072829906890265, 0.5228265849455143]) #np.zeros(shape = (output_nodes, 1))\n",
    "\n",
    "print(w2,b2, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-happiness",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-packing",
   "metadata": {},
   "source": [
    "**Forward feed before training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "perfect-license",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18786572, 0.4845507 , 0.32758358])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X[0, :]\n",
    "\n",
    "in_hidden_1 = w1.dot(x) + b1\n",
    "out_hidden_1 = sig(in_hidden_1)\n",
    "\n",
    "in_output_layer = w2.dot(out_hidden_1) + b2\n",
    "y_hat = softmax(in_output_layer)\n",
    "\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "curious-found",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = ys[0,:]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ruled-theology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5573426040225352"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_E(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-riding",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-delaware",
   "metadata": {},
   "source": [
    "**SGD Momentum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "standard-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "clean-samuel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.]\n",
      " [0.]]\n",
      "[0. 0.]\n",
      "[[0. 0.]\n",
      " [0. 0.]\n",
      " [0. 0.]]\n",
      "[0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "update_w1 = np.zeros(w1.shape)\n",
    "\n",
    "update_b1 = np.zeros(b1.shape)\n",
    "\n",
    "update_w2 = np.zeros(w2.shape)\n",
    "\n",
    "update_b2 = np.zeros(b2.shape)\n",
    "\n",
    "print(update_w1, update_b1, sep='\\n')\n",
    "print(update_w2, update_b2, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-visitor",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff04a8",
   "metadata": {},
   "source": [
    "**Total number of epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74c103e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e869d04",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-parking",
   "metadata": {},
   "source": [
    "**Backpropagation in ANNs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "experimental-strategy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss before training is 0.5573426040225352 -- epoch number 1\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,1) and (2,) not aligned: 1 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_22532\\907526829.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0merror_upto_softmax\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresh\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mgrad_w2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_upto_softmax\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mout_hidden_1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;31m#(3,2)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mgrad_b2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0merror_upto_softmax\u001b[0m \u001b[1;31m#(3,1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,1) and (2,) not aligned: 1 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(len(X)):\n",
    "    #------------------------------------------Forward Propagation-------------------------------------------------\n",
    "        x = X[i, :]\n",
    "        y = ys[i,:]\n",
    "        in_hidden_1 = w1.dot(x) + b1 #(2,1)\n",
    "        out_hidden_1 = sig(in_hidden_1) #(2,1)\n",
    "\n",
    "        in_output_layer = w2.dot(out_hidden_1) + b2 #(3,1)\n",
    "        y_hat = softmax(in_output_layer) #(3,1) [0.18786572274388938, 0.4845507011829411, 0.3275835760731695]\n",
    "        \n",
    "        loss = cross_E(y, y_hat)\n",
    "        print(f'loss before training is {loss} -- epoch number {epoch + 1}')\n",
    "        print('\\n')\n",
    "        \n",
    "    #-----------------------------------------Gradient Calculations via Back Propagation---------------------------\n",
    "\n",
    "        sd = softmax_dash(in_output_layer) #(3,3) [[ 0.15257219, -0.23478938, -0.107311  ],[-0.03529353,  0.24976132, -0.107311  ],[-0.03529353, -0.23478938,  0.22027258]]\n",
    "        ced = cross_E_grad(y, y_hat) #(3,1)\n",
    "        summ = np.sum(ced * sd, axis = 0) #(3,)\n",
    "        resh = summ.reshape((-1, 1)) #(3,1)\n",
    "        error_upto_softmax = resh\n",
    "        \n",
    "        grad_w2 = error_upto_softmax .dot( out_hidden_1.T ) #(3,2)\n",
    "        \n",
    "        grad_b2 = error_upto_softmax #(3,1)\n",
    "        \n",
    "        #-----------------------------------------c\n",
    "        \n",
    "        error_grad_upto_H1 = np.sum(error_upto_softmax * w2, axis = 0) .reshape((-1, 1)) #(2,1)\n",
    "        \n",
    "        grad_w1 = error_grad_upto_H1 * sig_dash(in_hidden_1) .dot( x.T ) #(2,1)\n",
    "        \n",
    "        grad_b1 = error_grad_upto_H1 * sig_dash(in_hidden_1) #(2,1)\n",
    "        \n",
    "    #-----------------------------------------Updating weights and biases via SGD Momentum------------------------\n",
    "\n",
    "        update_w1 = - learning_rate * grad_w1 + momentum * update_w1\n",
    "        w1 += update_w1 #(2,1)\n",
    "        \n",
    "        update_b1 = - learning_rate * grad_b1 + momentum * update_b1\n",
    "        b1 += update_b1 #(2,1)\n",
    "        \n",
    "        update_w2 = - learning_rate * grad_w2 + momentum * update_w2\n",
    "        w2 += update_w2 #(3,2)\n",
    "        \n",
    "        update_b2 = - learning_rate * grad_b2 + momentum * update_b2\n",
    "        b2 += update_b2 #(3,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-philippines",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-belief",
   "metadata": {},
   "source": [
    "**Forward feed after training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-province",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,2) (3,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_13864\\2255095917.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mout_hidden_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_hidden_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0min_output_layer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_hidden_1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_output_layer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,2) (3,) "
     ]
    }
   ],
   "source": [
    "in_hidden_1 = w1.dot(x) + b1\n",
    "out_hidden_1 = sig(in_hidden_1)\n",
    "\n",
    "in_output_layer = w2.dot(in_hidden_1) + b2\n",
    "y_hat = softmax(in_output_layer)\n",
    "\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "burning-jefferson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001991270523606741"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_E(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f257f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd068e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 2, 2, 0, 1, 1, 0, 0, 2]\n",
      "[0.02333333, 0.26333333, 0.86, 0.94666667, 0.30333333, 0.54, 0.42333333, 0.19, 0.17666667, 0.96666667]\n",
      "Predicted class labels: [0 0 0 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.input_layer_size = 1\n",
    "        self.hidden_layer_size = 2\n",
    "        self.output_layer_size = 3\n",
    "        self.W1 = np.array([[0.28401832, -0.95381398]]) #np.random.randn(self.input_layer_size, self.hidden_layer_size) #[[-0.946956],[-0.05371076]] here [[2.268696555647382, 1.0747582434460212]]\n",
    "        self.b1 = np.array([[-0.52433746, 0.33221849]]) #np.zeros((1, self.hidden_layer_size)) #[-0.04069894424931042, -0.8648014344296282] here [[0., 0.]]\n",
    "        self.W2 = np.array([[-0.15495577, 0.63793899, -0.71792529],[-0.56723879, -0.37206676, 0.49335413]]) #np.random.randn(self.hidden_layer_size, self.output_layer_size) #[[-0.01435154,  0.48572941],[0.17128856, 0.85747956],[ 0.08848815, -0.77120695]] here [[ 0.78696879, -0.5470661 ,  1.32080322],[-0.49238067, -0.46736653, -0.30174847]]\n",
    "        self.b2 = np.array([[0.36843569, 0.90728299, 0.52282658]]) #np.zeros((1, self.output_layer_size)) #[0.5863426622842711, 0.4967395061795983, 0.20838814081519974] here [[0., 0., 0.]]\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x)\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    def cross_entropy_loss(self, y_true, y_pred):\n",
    "        m = y_true.shape[0]\n",
    "        log_likelihood = -np.log(y_pred[range(m), y_true])\n",
    "        loss = np.sum(log_likelihood) / m\n",
    "        return loss\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def softmax_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for i in range(epochs):\n",
    "            for j in range(X.shape[0]):\n",
    "                # Forward propagation\n",
    "                x = X[j] # [0.02333333]\n",
    "                z1 = np.dot(x, self.W1) + self.b1 #[[-0.51771037,  0.30996283]]\n",
    "                a1 = self.sigmoid(z1) #[[0.37338778, 0.57687619]]\n",
    "                z2 = np.dot(a1, self.W2) + self.b2 #[[-0.01664945,  0.93084516,  0.5393663 ]]\n",
    "                a2 = self.softmax(z2) #[[0.18786572, 0.4845507 , 0.32758358]]\n",
    "\n",
    "                # Backpropagation\n",
    "                delta2 = a2\n",
    "                delta2[0, y[j]] -= 1 #[[-0.81213428,  0.4845507 ,  0.32758358]]\n",
    "                sigd = self.sigmoid_derivative(a1) #[[0.23396935, 0.24409005]]\n",
    "                dot = np.dot(delta2, self.W2.T) #[[0.19977815, 0.44200356]]\n",
    "                delta1 = sigd * dot #[[0.04674196, 0.10788867]]\n",
    "\n",
    "                # Update weights\n",
    "                self.W2 -= learning_rate * np.outer(a1, delta2) # here [[-0.12463167,  0.61984646, -0.73015686],[-0.5203887 , -0.40001934,  0.47445661]]\n",
    "                self.b2 -= learning_rate * delta2 # here [[0.44964912, 0.85882792, 0.49006822]]\n",
    "                self.W1 -= learning_rate * np.outer(x, delta1) # here [[ 0.28390926, -0.95406572]]\n",
    "                self.b1 -= learning_rate * delta1 # here [[-0.52901166,  0.32142962]]\n",
    "        \n",
    "    def predict(self, X):\n",
    "        z1 = np.dot(X, self.W1) + self.b1\n",
    "        a1 = self.sigmoid(z1)\n",
    "        z2 = np.dot(a1, self.W2) + self.b2\n",
    "        a2 = self.softmax(z2)\n",
    "        return np.argmax(a2, axis=1)\n",
    "\n",
    "# new_data_x = np.random.randint(1, 300, 200)\n",
    "# new_data_target = new_data_x // 100\n",
    "# print(new_data_target)\n",
    "# new_data_x = new_data_x / 300   \n",
    "# print(new_data_x)\n",
    "\n",
    "new_data_x = [0.02333333, 0.26333333, 0.86, 0.94666667, 0.30333333, 0.54, 0.42333333, 0.19, 0.17666667, 0.96666667]\n",
    "new_data_target = [0, 0, 2, 2, 0, 1, 1, 0, 0, 2]\n",
    "print(new_data_target)\n",
    "print(new_data_x)\n",
    "\n",
    "X_train = np.array(new_data_x).reshape(-1, 1)\n",
    "y_train = np.array(new_data_target)\n",
    "\n",
    "nn = NeuralNetwork()\n",
    "nn.train(X_train, y_train, epochs=500, learning_rate=0.1)\n",
    "X_test = np.array([0.0, 0.0, 0.000001, 0.5, 0.4, 0.8, 0.9]).reshape(-1, 1)\n",
    "y_pred = nn.predict(X_test)\n",
    "print(\"Predicted class labels:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de81b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, learning_rate):\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.learning_rate = learning_rate\n",
    "        \n",
    "        # Initialize weights\n",
    "        self.W1 = np.random.randn(self.input_size, self.hidden_size)\n",
    "        self.b1 = np.zeros((1, self.hidden_size))\n",
    "        self.W2 = np.random.randn(self.hidden_size, self.output_size)\n",
    "        self.b2 = np.zeros((1, self.output_size))\n",
    "        \n",
    "    def sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        exp_x = np.exp(x)\n",
    "        return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "    \n",
    "    def softmax_derivative(self, x):\n",
    "        s = x.reshape(-1,1)\n",
    "        return np.diagflat(s) - np.dot(s, s.T)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        # Hidden layer\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        \n",
    "        # Output layer\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        \n",
    "        return self.a2\n",
    "    \n",
    "    def backward(self, X, y, output):\n",
    "        # Output layer error\n",
    "        self.output_error = output - y\n",
    "        d_z2 = self.output_error * self.softmax_derivative(self.a2)\n",
    "        \n",
    "        # Hidden layer error\n",
    "        d_a1 = np.dot(d_z2, self.W2.T)\n",
    "        d_z1 = d_a1 * self.sigmoid_derivative(self.a1)\n",
    "        \n",
    "        # Update weights and biases\n",
    "        self.W2 -= self.learning_rate * np.dot(self.a1.T, d_z2)\n",
    "        self.b2 -= self.learning_rate * np.sum(d_z2, axis=0, keepdims=True)\n",
    "        self.W1 -= self.learning_rate * np.dot(X.T, d_z1)\n",
    "        self.b1 -= self.learning_rate * np.sum(d_z1, axis=0)\n",
    "        \n",
    "    def train(self, X, y, epochs):\n",
    "        for i in range(epochs):\n",
    "            for j in range(X.shape[0]):\n",
    "                output = self.forward(X[j])\n",
    "                self.backward(X[j], y[j], output)\n",
    "                \n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddbba199",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,1) and (3,3) not aligned: 1 (dim 1) != 3 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25740\\2644014061.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNeuralNetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.000001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25740\\62332639.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, epochs)\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25740\\62332639.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, X, y, output)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;31m# Update weights and biases\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_z2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb2\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_z2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW1\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_z1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,1) and (3,3) not aligned: 1 (dim 1) != 3 (dim 0)"
     ]
    }
   ],
   "source": [
    "X_train = np.array([0.88333333, 0.58, 0.91333333, 0.4, 0.74, 0.96, 0.51666667, 0.3, 0.69333333, 0.63666667])\n",
    "y_train = np.array([2, 1, 2, 1, 2, 2, 1, 0, 2, 1])\n",
    "\n",
    "nn = NeuralNetwork(1,2,3,0.1)\n",
    "nn.train(X_train.reshape(-1, 1), y_train.reshape(-1, 1), epochs=1000)\n",
    "X_test = np.array([0.0, 0.0, 0.000001, 0.5, 0.4, 0.8, 0.9]).reshape(-1, 1)\n",
    "y_pred = nn.predict(X_test)\n",
    "print(\"Predicted class labels:\", y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eaea5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class MultiClassNN:\n",
    "    def __init__(self):\n",
    "        self.input_size = 1\n",
    "        self.hidden_size = 2\n",
    "        self.output_size = 3\n",
    "        self.learning_rate = 0.1\n",
    "        self.epochs = 1500\n",
    "\n",
    "        self.W1 = np.array([[0.28401832, -0.95381398]]) #np.random.randn(self.input_layer_size, self.hidden_layer_size) #[[-0.946956],[-0.05371076]] here [[2.268696555647382, 1.0747582434460212]]\n",
    "        self.b1 = np.array([[-0.52433746, 0.33221849]]) #np.zeros((1, self.hidden_layer_size)) #[-0.04069894424931042, -0.8648014344296282] here [[0., 0.]]\n",
    "        self.W2 = np.array([[-0.15495577, 0.63793899, -0.71792529],[-0.56723879, -0.37206676, 0.49335413]]) #np.random.randn(self.hidden_layer_size, self.output_layer_size) #[[-0.01435154,  0.48572941],[0.17128856, 0.85747956],[ 0.08848815, -0.77120695]] here [[ 0.78696879, -0.5470661 ,  1.32080322],[-0.49238067, -0.46736653, -0.30174847]]\n",
    "        self.b2 = np.array([[0.36843569, 0.90728299, 0.52282658]]) #np.zeros((1, self.output_layer_size)) #[0.5863426622842711, 0.4967395061795983, 0.20838814081519974] here [[0., 0., 0.]]\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "    def softmax(self, z):\n",
    "        return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "\n",
    "    def cross_entropy_loss(self, y, y_hat):\n",
    "        return -np.sum(y * np.log(y_hat))\n",
    "        \n",
    "    def apply(self, x):\n",
    "        h_array = self.forward(x)\n",
    "        return h_array[-1]\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.z1 = np.dot(x, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.softmax(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, x, y, y_hat):\n",
    "        delta3 = y_hat - y\n",
    "        dW2 = np.dot(self.a1.T, delta3)\n",
    "        db2 = np.sum(delta3, axis=0)\n",
    "        delta2 = delta3.dot(self.W2.T) * self.a1 * (1 - self.a1)\n",
    "        dW1 = np.dot(x.T, delta2)\n",
    "        db1 = np.sum(delta2, axis=0)\n",
    "\n",
    "        self.W2 -= self.learning_rate * dW2\n",
    "        self.b2 -= self.learning_rate * db2\n",
    "        self.W1 -= self.learning_rate * dW1\n",
    "        self.b1 -= self.learning_rate * db1\n",
    "\n",
    "    def train(self, X, y):\n",
    "        costs = []\n",
    "        m = X.shape[0]\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            avg_cost = 0\n",
    "\n",
    "            for i in range(m):\n",
    "                x = X[i]\n",
    "                x = x.reshape(1, -1)\n",
    "                y_i = y[i]\n",
    "                y_i = y_i.reshape(1, -1)\n",
    "\n",
    "                y_hat = self.forward(x)\n",
    "                cost = self.cross_entropy_loss(y_i, y_hat)\n",
    "                self.backward(x, y_i, y_hat)\n",
    "\n",
    "                avg_cost += cost / m\n",
    "\n",
    "            costs.append(avg_cost)\n",
    "\n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a740a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgrammFiles\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86: RuntimeWarning: overflow encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "C:\\Users\\ilkhom-pc\\AppData\\Local\\Temp\\ipykernel_13864\\4125930933.py:23: RuntimeWarning: divide by zero encountered in log\n",
      "  return -np.sum(y * np.log(y_hat))\n",
      "C:\\Users\\ilkhom-pc\\AppData\\Local\\Temp\\ipykernel_13864\\4125930933.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
      "C:\\Users\\ilkhom-pc\\AppData\\Local\\Temp\\ipykernel_13864\\4125930933.py:20: RuntimeWarning: invalid value encountered in true_divide\n",
      "  return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "new_data_x = np.array([0.02333333, 0.26333333, 0.86, 0.94666667, 0.30333333, 0.54, 0.42333333, 0.19, 0.17666667, 0.96666667])\n",
    "new_data_target = np.array([0, 0, 2, 2, 0, 1, 1, 0, 0, 2])\n",
    "\n",
    "N = MultiClassNN()\n",
    "avg_cost_func = N.train(X=new_data_x.reshape(-1, 1), y=new_data_target.reshape(-1, 1))\n",
    "sns.lineplot(data=avg_cost_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de21aff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([nan, nan, nan]), array([nan, nan, nan]), array([nan, nan, nan])]\n"
     ]
    }
   ],
   "source": [
    "predictions = [N.apply([0.2]), N.apply([0.6]),N.apply([0.9])]\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5147a8decd31e7b15d80b003c7388619c1258d9dc84c7b27bb729bd71864e42d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
