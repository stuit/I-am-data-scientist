{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "catholic-advisory",
   "metadata": {},
   "source": [
    "**Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "broken-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-robinson",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-sensitivity",
   "metadata": {},
   "source": [
    "**Nodes in each layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indian-voice",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_nodes = 5\n",
    "hidden_1_nodes = 3\n",
    "hidden_2_nodes = 5\n",
    "output_nodes = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monetary-classics",
   "metadata": {},
   "source": [
    "-------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "threaded-advantage",
   "metadata": {},
   "source": [
    "**Inputs and true outputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cathedral-bunch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88],\n",
       "       [0.24],\n",
       "       [0.03],\n",
       "       [0.22],\n",
       "       [0.53]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.random.randint(1, 100, size = (input_nodes, 1)) / 100\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "continental-locking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([[0], [1], [0], [0]])\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-philip",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nuclear-mills",
   "metadata": {},
   "source": [
    "**Defining Activation functions and loss with their derivatives**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-hunger",
   "metadata": {},
   "source": [
    "Sigmoid for first hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compatible-stage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return 1/(1 + np.exp(-x))           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "western-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_dash(x):\n",
    "    return sig(x) * (1 - sig(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-affairs",
   "metadata": {},
   "source": [
    "Softmax for second hidden layer and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "minor-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x) / np.sum(np.exp(x))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adjustable-sword",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_dash(x):\n",
    "    \n",
    "    I = np.eye(x.shape[0])\n",
    "    \n",
    "    return softmax(x) * (I - softmax(x).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-reference",
   "metadata": {},
   "source": [
    "Categorical cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "synthetic-finder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_E(y_true, y_pred):\n",
    "    return -np.sum(y_true * np.log(y_pred + 10**-100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "macro-treasure",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_E_grad(y_true, y_pred):\n",
    "    return -y_true/(y_pred + 10**-100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-willow",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "removed-congo",
   "metadata": {},
   "source": [
    "**Random initialization of weights and biases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adjacent-appraisal",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = np.random.random(size = (hidden_1_nodes, input_nodes))\n",
    "b1 = np.zeros(shape = (hidden_1_nodes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vulnerable-interference",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = np.random.random(size = (hidden_2_nodes, hidden_1_nodes))\n",
    "b2 = np.zeros(shape = (hidden_2_nodes, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "commercial-machinery",
   "metadata": {},
   "outputs": [],
   "source": [
    "w3 = np.random.random(size = (output_nodes, hidden_2_nodes))\n",
    "b3 = np.zeros(shape = (output_nodes, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-happiness",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diagnostic-packing",
   "metadata": {},
   "source": [
    "**Forward feed before training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "perfect-license",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22154299],\n",
       "       [0.2905346 ],\n",
       "       [0.23804737],\n",
       "       [0.24987504]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_hidden_1 = w1.dot(x) + b1\n",
    "out_hidden_1 = sig(in_hidden_1)\n",
    "\n",
    "in_hidden_2 = w2.dot(out_hidden_1) + b2\n",
    "out_hidden_2 = softmax(in_hidden_2)\n",
    "\n",
    "in_output_layer = w3.dot(out_hidden_2) + b3\n",
    "y_hat = softmax(in_output_layer)\n",
    "\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "curious-found",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ruled-theology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2360326123452905"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_E(y, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-riding",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-delaware",
   "metadata": {},
   "source": [
    "**SGD Momentum**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "standard-orlando",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "momentum = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "clean-samuel",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_w1 = np.zeros(w1.shape)\n",
    "\n",
    "update_b1 = np.zeros(b1.shape)\n",
    "\n",
    "update_w2 = np.zeros(w2.shape)\n",
    "\n",
    "update_b2 = np.zeros(b2.shape)\n",
    "\n",
    "update_w3 = np.zeros(w3.shape)\n",
    "\n",
    "update_b3 = np.zeros(b3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varied-visitor",
   "metadata": {},
   "source": [
    "---------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ff04a8",
   "metadata": {},
   "source": [
    "**Total number of epochs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74c103e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e869d04",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absent-parking",
   "metadata": {},
   "source": [
    "**Backpropagation in ANNs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "experimental-strategy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss before training is 1.2360326123452905 -- epoch number 1\n",
      "\n",
      "\n",
      "loss before training is 1.2272601886539678 -- epoch number 2\n",
      "\n",
      "\n",
      "loss before training is 1.2107023401823842 -- epoch number 3\n",
      "\n",
      "\n",
      "loss before training is 1.1873387402582236 -- epoch number 4\n",
      "\n",
      "\n",
      "loss before training is 1.1581267572348306 -- epoch number 5\n",
      "\n",
      "\n",
      "loss before training is 1.1239907842101362 -- epoch number 6\n",
      "\n",
      "\n",
      "loss before training is 1.0858143749274538 -- epoch number 7\n",
      "\n",
      "\n",
      "loss before training is 1.0444341603351217 -- epoch number 8\n",
      "\n",
      "\n",
      "loss before training is 1.0006348855323508 -- epoch number 9\n",
      "\n",
      "\n",
      "loss before training is 0.9551451872946534 -- epoch number 10\n",
      "\n",
      "\n",
      "loss before training is 0.9086339463885449 -- epoch number 11\n",
      "\n",
      "\n",
      "loss before training is 0.8617072069352467 -- epoch number 12\n",
      "\n",
      "\n",
      "loss before training is 0.8149057622040771 -- epoch number 13\n",
      "\n",
      "\n",
      "loss before training is 0.7687035648418804 -- epoch number 14\n",
      "\n",
      "\n",
      "loss before training is 0.7235071322594603 -- epoch number 15\n",
      "\n",
      "\n",
      "loss before training is 0.6796560896120585 -- epoch number 16\n",
      "\n",
      "\n",
      "loss before training is 0.6374249319355463 -- epoch number 17\n",
      "\n",
      "\n",
      "loss before training is 0.5970260053355336 -- epoch number 18\n",
      "\n",
      "\n",
      "loss before training is 0.558613618561267 -- epoch number 19\n",
      "\n",
      "\n",
      "loss before training is 0.5222891146833272 -- epoch number 20\n",
      "\n",
      "\n",
      "loss before training is 0.48810666945972686 -- epoch number 21\n",
      "\n",
      "\n",
      "loss before training is 0.45607954572195136 -- epoch number 22\n",
      "\n",
      "\n",
      "loss before training is 0.42618652419409325 -- epoch number 23\n",
      "\n",
      "\n",
      "loss before training is 0.39837824835487695 -- epoch number 24\n",
      "\n",
      "\n",
      "loss before training is 0.3725832585449663 -- epoch number 25\n",
      "\n",
      "\n",
      "loss before training is 0.34871354093631096 -- epoch number 26\n",
      "\n",
      "\n",
      "loss before training is 0.3266694724334682 -- epoch number 27\n",
      "\n",
      "\n",
      "loss before training is 0.3063440963639652 -- epoch number 28\n",
      "\n",
      "\n",
      "loss before training is 0.28762671105857274 -- epoch number 29\n",
      "\n",
      "\n",
      "loss before training is 0.2704057912887027 -- epoch number 30\n",
      "\n",
      "\n",
      "loss before training is 0.25457129003098583 -- epoch number 31\n",
      "\n",
      "\n",
      "loss before training is 0.2400163855990244 -- epoch number 32\n",
      "\n",
      "\n",
      "loss before training is 0.22663874815946555 -- epoch number 33\n",
      "\n",
      "\n",
      "loss before training is 0.21434140181751668 -- epoch number 34\n",
      "\n",
      "\n",
      "loss before training is 0.20303325568125516 -- epoch number 35\n",
      "\n",
      "\n",
      "loss before training is 0.19262937130204072 -- epoch number 36\n",
      "\n",
      "\n",
      "loss before training is 0.183051026061145 -- epoch number 37\n",
      "\n",
      "\n",
      "loss before training is 0.17422562352151094 -- epoch number 38\n",
      "\n",
      "\n",
      "loss before training is 0.16608649326261724 -- epoch number 39\n",
      "\n",
      "\n",
      "loss before training is 0.15857261476723547 -- epoch number 40\n",
      "\n",
      "\n",
      "loss before training is 0.15162829281665202 -- epoch number 41\n",
      "\n",
      "\n",
      "loss before training is 0.1452028057013004 -- epoch number 42\n",
      "\n",
      "\n",
      "loss before training is 0.13925004238257085 -- epoch number 43\n",
      "\n",
      "\n",
      "loss before training is 0.13372814049529114 -- epoch number 44\n",
      "\n",
      "\n",
      "loss before training is 0.12859913366655917 -- epoch number 45\n",
      "\n",
      "\n",
      "loss before training is 0.12382861393543167 -- epoch number 46\n",
      "\n",
      "\n",
      "loss before training is 0.11938541297670577 -- epoch number 47\n",
      "\n",
      "\n",
      "loss before training is 0.1152413042536466 -- epoch number 48\n",
      "\n",
      "\n",
      "loss before training is 0.11137072705279667 -- epoch number 49\n",
      "\n",
      "\n",
      "loss before training is 0.10775053250528255 -- epoch number 50\n",
      "\n",
      "\n",
      "loss before training is 0.10435975110280628 -- epoch number 51\n",
      "\n",
      "\n",
      "loss before training is 0.10117938081455301 -- epoch number 52\n",
      "\n",
      "\n",
      "loss before training is 0.09819219465635422 -- epoch number 53\n",
      "\n",
      "\n",
      "loss before training is 0.09538256641805834 -- epoch number 54\n",
      "\n",
      "\n",
      "loss before training is 0.09273631318959574 -- epoch number 55\n",
      "\n",
      "\n",
      "loss before training is 0.0902405533177648 -- epoch number 56\n",
      "\n",
      "\n",
      "loss before training is 0.08788357845679885 -- epoch number 57\n",
      "\n",
      "\n",
      "loss before training is 0.08565473843299329 -- epoch number 58\n",
      "\n",
      "\n",
      "loss before training is 0.08354433771728453 -- epoch number 59\n",
      "\n",
      "\n",
      "loss before training is 0.08154354238235215 -- epoch number 60\n",
      "\n",
      "\n",
      "loss before training is 0.0796442965074282 -- epoch number 61\n",
      "\n",
      "\n",
      "loss before training is 0.07783924708083736 -- epoch number 62\n",
      "\n",
      "\n",
      "loss before training is 0.07612167653486328 -- epoch number 63\n",
      "\n",
      "\n",
      "loss before training is 0.07448544212821653 -- epoch number 64\n",
      "\n",
      "\n",
      "loss before training is 0.0729249214671742 -- epoch number 65\n",
      "\n",
      "\n",
      "loss before training is 0.07143496352682713 -- epoch number 66\n",
      "\n",
      "\n",
      "loss before training is 0.07001084459860844 -- epoch number 67\n",
      "\n",
      "\n",
      "loss before training is 0.06864822864942938 -- epoch number 68\n",
      "\n",
      "\n",
      "loss before training is 0.06734313163144874 -- epoch number 69\n",
      "\n",
      "\n",
      "loss before training is 0.06609188933008801 -- epoch number 70\n",
      "\n",
      "\n",
      "loss before training is 0.06489112838163626 -- epoch number 71\n",
      "\n",
      "\n",
      "loss before training is 0.06373774013110188 -- epoch number 72\n",
      "\n",
      "\n",
      "loss before training is 0.06262885703617029 -- epoch number 73\n",
      "\n",
      "\n",
      "loss before training is 0.06156183135463165 -- epoch number 74\n",
      "\n",
      "\n",
      "loss before training is 0.06053421588076687 -- epoch number 75\n",
      "\n",
      "\n",
      "loss before training is 0.059543746521279174 -- epoch number 76\n",
      "\n",
      "\n",
      "loss before training is 0.05858832652373454 -- epoch number 77\n",
      "\n",
      "\n",
      "loss before training is 0.05766601219039808 -- epoch number 78\n",
      "\n",
      "\n",
      "loss before training is 0.056774999928112496 -- epoch number 79\n",
      "\n",
      "\n",
      "loss before training is 0.055913614500667584 -- epoch number 80\n",
      "\n",
      "\n",
      "loss before training is 0.05508029836418224 -- epoch number 81\n",
      "\n",
      "\n",
      "loss before training is 0.054273601978558995 -- epoch number 82\n",
      "\n",
      "\n",
      "loss before training is 0.05349217499922664 -- epoch number 83\n",
      "\n",
      "\n",
      "loss before training is 0.05273475826333621 -- epoch number 84\n",
      "\n",
      "\n",
      "loss before training is 0.05200017649344429 -- epoch number 85\n",
      "\n",
      "\n",
      "loss before training is 0.05128733164960441 -- epoch number 86\n",
      "\n",
      "\n",
      "loss before training is 0.05059519686786656 -- epoch number 87\n",
      "\n",
      "\n",
      "loss before training is 0.04992281092944769 -- epoch number 88\n",
      "\n",
      "\n",
      "loss before training is 0.0492692732104836 -- epoch number 89\n",
      "\n",
      "\n",
      "loss before training is 0.0486337390672805 -- epoch number 90\n",
      "\n",
      "\n",
      "loss before training is 0.048015415616484196 -- epoch number 91\n",
      "\n",
      "\n",
      "loss before training is 0.04741355787360244 -- epoch number 92\n",
      "\n",
      "\n",
      "loss before training is 0.046827465216918523 -- epoch number 93\n",
      "\n",
      "\n",
      "loss before training is 0.046256478147056225 -- epoch number 94\n",
      "\n",
      "\n",
      "loss before training is 0.045699975315349875 -- epoch number 95\n",
      "\n",
      "\n",
      "loss before training is 0.04515737079677239 -- epoch number 96\n",
      "\n",
      "\n",
      "loss before training is 0.044628111585498384 -- epoch number 97\n",
      "\n",
      "\n",
      "loss before training is 0.044111675293273644 -- epoch number 98\n",
      "\n",
      "\n",
      "loss before training is 0.04360756803265582 -- epoch number 99\n",
      "\n",
      "\n",
      "loss before training is 0.04311532246886264 -- epoch number 100\n",
      "\n",
      "\n",
      "loss before training is 0.042634496025514945 -- epoch number 101\n",
      "\n",
      "\n",
      "loss before training is 0.042164669230914865 -- epoch number 102\n",
      "\n",
      "\n",
      "loss before training is 0.04170544419274699 -- epoch number 103\n",
      "\n",
      "\n",
      "loss before training is 0.041256443190210795 -- epoch number 104\n",
      "\n",
      "\n",
      "loss before training is 0.04081730737358723 -- epoch number 105\n",
      "\n",
      "\n",
      "loss before training is 0.04038769556217176 -- epoch number 106\n",
      "\n",
      "\n",
      "loss before training is 0.03996728313231018 -- epoch number 107\n",
      "\n",
      "\n",
      "loss before training is 0.03955576098803436 -- epoch number 108\n",
      "\n",
      "\n",
      "loss before training is 0.03915283460745199 -- epoch number 109\n",
      "\n",
      "\n",
      "loss before training is 0.03875822315867004 -- epoch number 110\n",
      "\n",
      "\n",
      "loss before training is 0.03837165867957035 -- epoch number 111\n",
      "\n",
      "\n",
      "loss before training is 0.03799288531626257 -- epoch number 112\n",
      "\n",
      "\n",
      "loss before training is 0.03762165861549276 -- epoch number 113\n",
      "\n",
      "\n",
      "loss before training is 0.037257744866695516 -- epoch number 114\n",
      "\n",
      "\n",
      "loss before training is 0.036900920489750515 -- epoch number 115\n",
      "\n",
      "\n",
      "loss before training is 0.03655097146485041 -- epoch number 116\n",
      "\n",
      "\n",
      "loss before training is 0.03620769280118087 -- epoch number 117\n",
      "\n",
      "\n",
      "loss before training is 0.03587088804141088 -- epoch number 118\n",
      "\n",
      "\n",
      "loss before training is 0.03554036879923333 -- epoch number 119\n",
      "\n",
      "\n",
      "loss before training is 0.035215954327432304 -- epoch number 120\n",
      "\n",
      "\n",
      "loss before training is 0.03489747111416631 -- epoch number 121\n",
      "\n",
      "\n",
      "loss before training is 0.03458475250534743 -- epoch number 122\n",
      "\n",
      "\n",
      "loss before training is 0.034277638351167296 -- epoch number 123\n",
      "\n",
      "\n",
      "loss before training is 0.033975974674991284 -- epoch number 124\n",
      "\n",
      "\n",
      "loss before training is 0.033679613362973655 -- epoch number 125\n",
      "\n",
      "\n",
      "loss before training is 0.03338841187289425 -- epoch number 126\n",
      "\n",
      "\n",
      "loss before training is 0.03310223296082668 -- epoch number 127\n",
      "\n",
      "\n",
      "loss before training is 0.03282094442436497 -- epoch number 128\n",
      "\n",
      "\n",
      "loss before training is 0.03254441886123658 -- epoch number 129\n",
      "\n",
      "\n",
      "loss before training is 0.03227253344222092 -- epoch number 130\n",
      "\n",
      "\n",
      "loss before training is 0.03200516969737884 -- epoch number 131\n",
      "\n",
      "\n",
      "loss before training is 0.03174221331467159 -- epoch number 132\n",
      "\n",
      "\n",
      "loss before training is 0.03148355395012882 -- epoch number 133\n",
      "\n",
      "\n",
      "loss before training is 0.031229085048777545 -- epoch number 134\n",
      "\n",
      "\n",
      "loss before training is 0.030978703675615053 -- epoch number 135\n",
      "\n",
      "\n",
      "loss before training is 0.030732310355953377 -- epoch number 136\n",
      "\n",
      "\n",
      "loss before training is 0.030489808924524173 -- epoch number 137\n",
      "\n",
      "\n",
      "loss before training is 0.03025110638276697 -- epoch number 138\n",
      "\n",
      "\n",
      "loss before training is 0.03001611276377759 -- epoch number 139\n",
      "\n",
      "\n",
      "loss before training is 0.0297847410044216 -- epoch number 140\n",
      "\n",
      "\n",
      "loss before training is 0.029556906824164095 -- epoch number 141\n",
      "\n",
      "\n",
      "loss before training is 0.029332528610188202 -- epoch number 142\n",
      "\n",
      "\n",
      "loss before training is 0.02911152730841986 -- epoch number 143\n",
      "\n",
      "\n",
      "loss before training is 0.028893826320086368 -- epoch number 144\n",
      "\n",
      "\n",
      "loss before training is 0.02867935140347889 -- epoch number 145\n",
      "\n",
      "\n",
      "loss before training is 0.028468030580601277 -- epoch number 146\n",
      "\n",
      "\n",
      "loss before training is 0.02825979404841393 -- epoch number 147\n",
      "\n",
      "\n",
      "loss before training is 0.028054574094402176 -- epoch number 148\n",
      "\n",
      "\n",
      "loss before training is 0.027852305016214034 -- epoch number 149\n",
      "\n",
      "\n",
      "loss before training is 0.027652923045133913 -- epoch number 150\n",
      "\n",
      "\n",
      "loss before training is 0.027456366273168168 -- epoch number 151\n",
      "\n",
      "\n",
      "loss before training is 0.027262574583542372 -- epoch number 152\n",
      "\n",
      "\n",
      "loss before training is 0.027071489584413716 -- epoch number 153\n",
      "\n",
      "\n",
      "loss before training is 0.026883054545622 -- epoch number 154\n",
      "\n",
      "\n",
      "loss before training is 0.02669721433830987 -- epoch number 155\n",
      "\n",
      "\n",
      "loss before training is 0.026513915377257044 -- epoch number 156\n",
      "\n",
      "\n",
      "loss before training is 0.026333105565780727 -- epoch number 157\n",
      "\n",
      "\n",
      "loss before training is 0.02615473424306478 -- epoch number 158\n",
      "\n",
      "\n",
      "loss before training is 0.025978752133788998 -- epoch number 159\n",
      "\n",
      "\n",
      "loss before training is 0.025805111299937303 -- epoch number 160\n",
      "\n",
      "\n",
      "loss before training is 0.02563376509467109 -- epoch number 161\n",
      "\n",
      "\n",
      "loss before training is 0.025464668118162365 -- epoch number 162\n",
      "\n",
      "\n",
      "loss before training is 0.025297776175286085 -- epoch number 163\n",
      "\n",
      "\n",
      "loss before training is 0.025133046235075642 -- epoch number 164\n",
      "\n",
      "\n",
      "loss before training is 0.024970436391856612 -- epoch number 165\n",
      "\n",
      "\n",
      "loss before training is 0.024809905827972795 -- epoch number 166\n",
      "\n",
      "\n",
      "loss before training is 0.024651414778026636 -- epoch number 167\n",
      "\n",
      "\n",
      "loss before training is 0.02449492449456159 -- epoch number 168\n",
      "\n",
      "\n",
      "loss before training is 0.02434039721511401 -- epoch number 169\n",
      "\n",
      "\n",
      "loss before training is 0.02418779613057112 -- epoch number 170\n",
      "\n",
      "\n",
      "loss before training is 0.024037085354774175 -- epoch number 171\n",
      "\n",
      "\n",
      "loss before training is 0.023888229895302995 -- epoch number 172\n",
      "\n",
      "\n",
      "loss before training is 0.023741195625393736 -- epoch number 173\n",
      "\n",
      "\n",
      "loss before training is 0.023595949256931446 -- epoch number 174\n",
      "\n",
      "\n",
      "loss before training is 0.02345245831447208 -- epoch number 175\n",
      "\n",
      "\n",
      "loss before training is 0.023310691110244846 -- epoch number 176\n",
      "\n",
      "\n",
      "loss before training is 0.023170616720092366 -- epoch number 177\n",
      "\n",
      "\n",
      "loss before training is 0.023032204960304635 -- epoch number 178\n",
      "\n",
      "\n",
      "loss before training is 0.022895426365309664 -- epoch number 179\n",
      "\n",
      "\n",
      "loss before training is 0.02276025216618075 -- epoch number 180\n",
      "\n",
      "\n",
      "loss before training is 0.022626654269925793 -- epoch number 181\n",
      "\n",
      "\n",
      "loss before training is 0.022494605239525962 -- epoch number 182\n",
      "\n",
      "\n",
      "loss before training is 0.022364078274688542 -- epoch number 183\n",
      "\n",
      "\n",
      "loss before training is 0.022235047193286103 -- epoch number 184\n",
      "\n",
      "\n",
      "loss before training is 0.022107486413451893 -- epoch number 185\n",
      "\n",
      "\n",
      "loss before training is 0.021981370936305304 -- epoch number 186\n",
      "\n",
      "\n",
      "loss before training is 0.021856676329277052 -- epoch number 187\n",
      "\n",
      "\n",
      "loss before training is 0.02173337871001467 -- epoch number 188\n",
      "\n",
      "\n",
      "loss before training is 0.021611454730841147 -- epoch number 189\n",
      "\n",
      "\n",
      "loss before training is 0.0214908815637448 -- epoch number 190\n",
      "\n",
      "\n",
      "loss before training is 0.02137163688587903 -- epoch number 191\n",
      "\n",
      "\n",
      "loss before training is 0.021253698865551267 -- epoch number 192\n",
      "\n",
      "\n",
      "loss before training is 0.02113704614868187 -- epoch number 193\n",
      "\n",
      "\n",
      "loss before training is 0.021021657845714768 -- epoch number 194\n",
      "\n",
      "\n",
      "loss before training is 0.02090751351896052 -- epoch number 195\n",
      "\n",
      "\n",
      "loss before training is 0.020794593170356042 -- epoch number 196\n",
      "\n",
      "\n",
      "loss before training is 0.02068287722962574 -- epoch number 197\n",
      "\n",
      "\n",
      "loss before training is 0.02057234654282622 -- epoch number 198\n",
      "\n",
      "\n",
      "loss before training is 0.020462982361261102 -- epoch number 199\n",
      "\n",
      "\n",
      "loss before training is 0.020354766330752554 -- epoch number 200\n",
      "\n",
      "\n",
      "loss before training is 0.020247680481255293 -- epoch number 201\n",
      "\n",
      "\n",
      "loss before training is 0.020141707216799344 -- epoch number 202\n",
      "\n",
      "\n",
      "loss before training is 0.02003682930575114 -- epoch number 203\n",
      "\n",
      "\n",
      "loss before training is 0.01993302987137922 -- epoch number 204\n",
      "\n",
      "\n",
      "loss before training is 0.019830292382714745 -- epoch number 205\n",
      "\n",
      "\n",
      "loss before training is 0.01972860064569619 -- epoch number 206\n",
      "\n",
      "\n",
      "loss before training is 0.01962793879458489 -- epoch number 207\n",
      "\n",
      "\n",
      "loss before training is 0.01952829128364638 -- epoch number 208\n",
      "\n",
      "\n",
      "loss before training is 0.019429642879084066 -- epoch number 209\n",
      "\n",
      "\n",
      "loss before training is 0.019331978651217267 -- epoch number 210\n",
      "\n",
      "\n",
      "loss before training is 0.01923528396689607 -- epoch number 211\n",
      "\n",
      "\n",
      "loss before training is 0.019139544482143868 -- epoch number 212\n",
      "\n",
      "\n",
      "loss before training is 0.01904474613501792 -- epoch number 213\n",
      "\n",
      "\n",
      "loss before training is 0.018950875138684164 -- epoch number 214\n",
      "\n",
      "\n",
      "loss before training is 0.018857917974693706 -- epoch number 215\n",
      "\n",
      "\n",
      "loss before training is 0.018765861386460057 -- epoch number 216\n",
      "\n",
      "\n",
      "loss before training is 0.018674692372923064 -- epoch number 217\n",
      "\n",
      "\n",
      "loss before training is 0.01858439818240144 -- epoch number 218\n",
      "\n",
      "\n",
      "loss before training is 0.018494966306618454 -- epoch number 219\n",
      "\n",
      "\n",
      "loss before training is 0.018406384474903153 -- epoch number 220\n",
      "\n",
      "\n",
      "loss before training is 0.018318640648556053 -- epoch number 221\n",
      "\n",
      "\n",
      "loss before training is 0.01823172301537438 -- epoch number 222\n",
      "\n",
      "\n",
      "loss before training is 0.01814561998433438 -- epoch number 223\n",
      "\n",
      "\n",
      "loss before training is 0.018060320180423146 -- epoch number 224\n",
      "\n",
      "\n",
      "loss before training is 0.017975812439612514 -- epoch number 225\n",
      "\n",
      "\n",
      "loss before training is 0.017892085803978504 -- epoch number 226\n",
      "\n",
      "\n",
      "loss before training is 0.017809129516952012 -- epoch number 227\n",
      "\n",
      "\n",
      "loss before training is 0.017726933018702092 -- epoch number 228\n",
      "\n",
      "\n",
      "loss before training is 0.017645485941647318 -- epoch number 229\n",
      "\n",
      "\n",
      "loss before training is 0.01756477810608861 -- epoch number 230\n",
      "\n",
      "\n",
      "loss before training is 0.017484799515962417 -- epoch number 231\n",
      "\n",
      "\n",
      "loss before training is 0.01740554035470701 -- epoch number 232\n",
      "\n",
      "\n",
      "loss before training is 0.017326990981242938 -- epoch number 233\n",
      "\n",
      "\n",
      "loss before training is 0.017249141926059672 -- epoch number 234\n",
      "\n",
      "\n",
      "loss before training is 0.017171983887407965 -- epoch number 235\n",
      "\n",
      "\n",
      "loss before training is 0.017095507727592024 -- epoch number 236\n",
      "\n",
      "\n",
      "loss before training is 0.017019704469362348 -- epoch number 237\n",
      "\n",
      "\n",
      "loss before training is 0.016944565292401167 -- epoch number 238\n",
      "\n",
      "\n",
      "loss before training is 0.016870081529902162 -- epoch number 239\n",
      "\n",
      "\n",
      "loss before training is 0.016796244665238175 -- epoch number 240\n",
      "\n",
      "\n",
      "loss before training is 0.01672304632871753 -- epoch number 241\n",
      "\n",
      "\n",
      "loss before training is 0.016650478294420394 -- epoch number 242\n",
      "\n",
      "\n",
      "loss before training is 0.01657853247712233 -- epoch number 243\n",
      "\n",
      "\n",
      "loss before training is 0.016507200929292493 -- epoch number 244\n",
      "\n",
      "\n",
      "loss before training is 0.016436475838169935 -- epoch number 245\n",
      "\n",
      "\n",
      "loss before training is 0.016366349522914363 -- epoch number 246\n",
      "\n",
      "\n",
      "loss before training is 0.01629681443182968 -- epoch number 247\n",
      "\n",
      "\n",
      "loss before training is 0.01622786313965611 -- epoch number 248\n",
      "\n",
      "\n",
      "loss before training is 0.016159488344932246 -- epoch number 249\n",
      "\n",
      "\n",
      "loss before training is 0.016091682867421013 -- epoch number 250\n",
      "\n",
      "\n",
      "loss before training is 0.01602443964560148 -- epoch number 251\n",
      "\n",
      "\n",
      "loss before training is 0.015957751734221884 -- epoch number 252\n",
      "\n",
      "\n",
      "loss before training is 0.015891612301913036 -- epoch number 253\n",
      "\n",
      "\n",
      "loss before training is 0.0158260146288612 -- epoch number 254\n",
      "\n",
      "\n",
      "loss before training is 0.015760952104537873 -- epoch number 255\n",
      "\n",
      "\n",
      "loss before training is 0.015696418225483788 -- epoch number 256\n",
      "\n",
      "\n",
      "loss before training is 0.01563240659314697 -- epoch number 257\n",
      "\n",
      "\n",
      "loss before training is 0.015568910911775587 -- epoch number 258\n",
      "\n",
      "\n",
      "loss before training is 0.015505924986357186 -- epoch number 259\n",
      "\n",
      "\n",
      "loss before training is 0.015443442720611525 -- epoch number 260\n",
      "\n",
      "\n",
      "loss before training is 0.015381458115028569 -- epoch number 261\n",
      "\n",
      "\n",
      "loss before training is 0.015319965264955078 -- epoch number 262\n",
      "\n",
      "\n",
      "loss before training is 0.015258958358723772 -- epoch number 263\n",
      "\n",
      "\n",
      "loss before training is 0.015198431675830308 -- epoch number 264\n",
      "\n",
      "\n",
      "loss before training is 0.015138379585151001 -- epoch number 265\n",
      "\n",
      "\n",
      "loss before training is 0.015078796543201831 -- epoch number 266\n",
      "\n",
      "\n",
      "loss before training is 0.015019677092438451 -- epoch number 267\n",
      "\n",
      "\n",
      "loss before training is 0.014961015859597913 -- epoch number 268\n",
      "\n",
      "\n",
      "loss before training is 0.014902807554073976 -- epoch number 269\n",
      "\n",
      "\n",
      "loss before training is 0.014845046966335634 -- epoch number 270\n",
      "\n",
      "\n",
      "loss before training is 0.014787728966376626 -- epoch number 271\n",
      "\n",
      "\n",
      "loss before training is 0.014730848502204503 -- epoch number 272\n",
      "\n",
      "\n",
      "loss before training is 0.014674400598361363 -- epoch number 273\n",
      "\n",
      "\n",
      "loss before training is 0.014618380354479201 -- epoch number 274\n",
      "\n",
      "\n",
      "loss before training is 0.014562782943868912 -- epoch number 275\n",
      "\n",
      "\n",
      "loss before training is 0.014507603612138502 -- epoch number 276\n",
      "\n",
      "\n",
      "loss before training is 0.014452837675845579 -- epoch number 277\n",
      "\n",
      "\n",
      "loss before training is 0.014398480521176153 -- epoch number 278\n",
      "\n",
      "\n",
      "loss before training is 0.014344527602656957 -- epoch number 279\n",
      "\n",
      "\n",
      "loss before training is 0.014290974441892682 -- epoch number 280\n",
      "\n",
      "\n",
      "loss before training is 0.01423781662633396 -- epoch number 281\n",
      "\n",
      "\n",
      "loss before training is 0.014185049808069847 -- epoch number 282\n",
      "\n",
      "\n",
      "loss before training is 0.014132669702649646 -- epoch number 283\n",
      "\n",
      "\n",
      "loss before training is 0.014080672087927607 -- epoch number 284\n",
      "\n",
      "\n",
      "loss before training is 0.014029052802935102 -- epoch number 285\n",
      "\n",
      "\n",
      "loss before training is 0.013977807746775383 -- epoch number 286\n",
      "\n",
      "\n",
      "loss before training is 0.013926932877544995 -- epoch number 287\n",
      "\n",
      "\n",
      "loss before training is 0.013876424211273426 -- epoch number 288\n",
      "\n",
      "\n",
      "loss before training is 0.013826277820891849 -- epoch number 289\n",
      "\n",
      "\n",
      "loss before training is 0.013776489835218592 -- epoch number 290\n",
      "\n",
      "\n",
      "loss before training is 0.013727056437969579 -- epoch number 291\n",
      "\n",
      "\n",
      "loss before training is 0.013677973866787391 -- epoch number 292\n",
      "\n",
      "\n",
      "loss before training is 0.013629238412292775 -- epoch number 293\n",
      "\n",
      "\n",
      "loss before training is 0.013580846417155505 -- epoch number 294\n",
      "\n",
      "\n",
      "loss before training is 0.013532794275182817 -- epoch number 295\n",
      "\n",
      "\n",
      "loss before training is 0.013485078430432113 -- epoch number 296\n",
      "\n",
      "\n",
      "loss before training is 0.013437695376335126 -- epoch number 297\n",
      "\n",
      "\n",
      "loss before training is 0.013390641654845853 -- epoch number 298\n",
      "\n",
      "\n",
      "loss before training is 0.013343913855603623 -- epoch number 299\n",
      "\n",
      "\n",
      "loss before training is 0.013297508615114645 -- epoch number 300\n",
      "\n",
      "\n",
      "loss before training is 0.01325142261594895 -- epoch number 301\n",
      "\n",
      "\n",
      "loss before training is 0.013205652585954228 -- epoch number 302\n",
      "\n",
      "\n",
      "loss before training is 0.013160195297487277 -- epoch number 303\n",
      "\n",
      "\n",
      "loss before training is 0.013115047566658936 -- epoch number 304\n",
      "\n",
      "\n",
      "loss before training is 0.013070206252595366 -- epoch number 305\n",
      "\n",
      "\n",
      "loss before training is 0.013025668256714914 -- epoch number 306\n",
      "\n",
      "\n",
      "loss before training is 0.012981430522016814 -- epoch number 307\n",
      "\n",
      "\n",
      "loss before training is 0.012937490032388801 -- epoch number 308\n",
      "\n",
      "\n",
      "loss before training is 0.012893843811923848 -- epoch number 309\n",
      "\n",
      "\n",
      "loss before training is 0.012850488924253087 -- epoch number 310\n",
      "\n",
      "\n",
      "loss before training is 0.012807422471892657 -- epoch number 311\n",
      "\n",
      "\n",
      "loss before training is 0.012764641595599755 -- epoch number 312\n",
      "\n",
      "\n",
      "loss before training is 0.012722143473746622 -- epoch number 313\n",
      "\n",
      "\n",
      "loss before training is 0.012679925321703155 -- epoch number 314\n",
      "\n",
      "\n",
      "loss before training is 0.012637984391231483 -- epoch number 315\n",
      "\n",
      "\n",
      "loss before training is 0.012596317969895753 -- epoch number 316\n",
      "\n",
      "\n",
      "loss before training is 0.012554923380479385 -- epoch number 317\n",
      "\n",
      "\n",
      "loss before training is 0.012513797980416397 -- epoch number 318\n",
      "\n",
      "\n",
      "loss before training is 0.012472939161232629 -- epoch number 319\n",
      "\n",
      "\n",
      "loss before training is 0.012432344347996982 -- epoch number 320\n",
      "\n",
      "\n",
      "loss before training is 0.012392010998786144 -- epoch number 321\n",
      "\n",
      "\n",
      "loss before training is 0.012351936604155825 -- epoch number 322\n",
      "\n",
      "\n",
      "loss before training is 0.012312118686624435 -- epoch number 323\n",
      "\n",
      "\n",
      "loss before training is 0.012272554800166069 -- epoch number 324\n",
      "\n",
      "\n",
      "loss before training is 0.012233242529712684 -- epoch number 325\n",
      "\n",
      "\n",
      "loss before training is 0.01219417949066688 -- epoch number 326\n",
      "\n",
      "\n",
      "loss before training is 0.012155363328422526 -- epoch number 327\n",
      "\n",
      "\n",
      "loss before training is 0.0121167917178943 -- epoch number 328\n",
      "\n",
      "\n",
      "loss before training is 0.012078462363058286 -- epoch number 329\n",
      "\n",
      "\n",
      "loss before training is 0.012040372996497685 -- epoch number 330\n",
      "\n",
      "\n",
      "loss before training is 0.012002521378960452 -- epoch number 331\n",
      "\n",
      "\n",
      "loss before training is 0.011964905298922695 -- epoch number 332\n",
      "\n",
      "\n",
      "loss before training is 0.01192752257216087 -- epoch number 333\n",
      "\n",
      "\n",
      "loss before training is 0.011890371041333073 -- epoch number 334\n",
      "\n",
      "\n",
      "loss before training is 0.011853448575565525 -- epoch number 335\n",
      "\n",
      "\n",
      "loss before training is 0.011816753070049047 -- epoch number 336\n",
      "\n",
      "\n",
      "loss before training is 0.01178028244564206 -- epoch number 337\n",
      "\n",
      "\n",
      "loss before training is 0.011744034648480187 -- epoch number 338\n",
      "\n",
      "\n",
      "loss before training is 0.011708007649593172 -- epoch number 339\n",
      "\n",
      "\n",
      "loss before training is 0.011672199444530735 -- epoch number 340\n",
      "\n",
      "\n",
      "loss before training is 0.01163660805299146 -- epoch number 341\n",
      "\n",
      "\n",
      "loss before training is 0.011601231518461529 -- epoch number 342\n",
      "\n",
      "\n",
      "loss before training is 0.011566067907858706 -- epoch number 343\n",
      "\n",
      "\n",
      "loss before training is 0.011531115311182687 -- epoch number 344\n",
      "\n",
      "\n",
      "loss before training is 0.01149637184117191 -- epoch number 345\n",
      "\n",
      "\n",
      "loss before training is 0.011461835632966405 -- epoch number 346\n",
      "\n",
      "\n",
      "loss before training is 0.011427504843776078 -- epoch number 347\n",
      "\n",
      "\n",
      "loss before training is 0.011393377652556698 -- epoch number 348\n",
      "\n",
      "\n",
      "loss before training is 0.01135945225968863 -- epoch number 349\n",
      "\n",
      "\n",
      "loss before training is 0.011325726886663931 -- epoch number 350\n",
      "\n",
      "\n",
      "loss before training is 0.011292199775777868 -- epoch number 351\n",
      "\n",
      "\n",
      "loss before training is 0.01125886918982531 -- epoch number 352\n",
      "\n",
      "\n",
      "loss before training is 0.011225733411803435 -- epoch number 353\n",
      "\n",
      "\n",
      "loss before training is 0.011192790744618653 -- epoch number 354\n",
      "\n",
      "\n",
      "loss before training is 0.011160039510799706 -- epoch number 355\n",
      "\n",
      "\n",
      "loss before training is 0.011127478052214526 -- epoch number 356\n",
      "\n",
      "\n",
      "loss before training is 0.011095104729792592 -- epoch number 357\n",
      "\n",
      "\n",
      "loss before training is 0.011062917923252065 -- epoch number 358\n",
      "\n",
      "\n",
      "loss before training is 0.011030916030831946 -- epoch number 359\n",
      "\n",
      "\n",
      "loss before training is 0.010999097469028109 -- epoch number 360\n",
      "\n",
      "\n",
      "loss before training is 0.010967460672333248 -- epoch number 361\n",
      "\n",
      "\n",
      "loss before training is 0.010936004092983696 -- epoch number 362\n",
      "\n",
      "\n",
      "loss before training is 0.010904726200708157 -- epoch number 363\n",
      "\n",
      "\n",
      "loss before training is 0.0108736254824807 -- epoch number 364\n",
      "\n",
      "\n",
      "loss before training is 0.010842700442280286 -- epoch number 365\n",
      "\n",
      "\n",
      "loss before training is 0.010811949600851946 -- epoch number 366\n",
      "\n",
      "\n",
      "loss before training is 0.010781371495471585 -- epoch number 367\n",
      "\n",
      "\n",
      "loss before training is 0.010750964679718717 -- epoch number 368\n",
      "\n",
      "\n",
      "loss before training is 0.010720727723246634 -- epoch number 369\n",
      "\n",
      "\n",
      "loss before training is 0.010690659211562762 -- epoch number 370\n",
      "\n",
      "\n",
      "loss before training is 0.010660757745808904 -- epoch number 371\n",
      "\n",
      "\n",
      "loss before training is 0.01063102194254505 -- epoch number 372\n",
      "\n",
      "\n",
      "loss before training is 0.010601450433538788 -- epoch number 373\n",
      "\n",
      "\n",
      "loss before training is 0.010572041865557168 -- epoch number 374\n",
      "\n",
      "\n",
      "loss before training is 0.010542794900160662 -- epoch number 375\n",
      "\n",
      "\n",
      "loss before training is 0.010513708213503408 -- epoch number 376\n",
      "\n",
      "\n",
      "loss before training is 0.010484780496133963 -- epoch number 377\n",
      "\n",
      "\n",
      "loss before training is 0.010456010452800096 -- epoch number 378\n",
      "\n",
      "\n",
      "loss before training is 0.010427396802257911 -- epoch number 379\n",
      "\n",
      "\n",
      "loss before training is 0.0103989382770824 -- epoch number 380\n",
      "\n",
      "\n",
      "loss before training is 0.010370633623482797 -- epoch number 381\n",
      "\n",
      "\n",
      "loss before training is 0.01034248160111845 -- epoch number 382\n",
      "\n",
      "\n",
      "loss before training is 0.010314480982920274 -- epoch number 383\n",
      "\n",
      "\n",
      "loss before training is 0.010286630554913054 -- epoch number 384\n",
      "\n",
      "\n",
      "loss before training is 0.0102589291160421 -- epoch number 385\n",
      "\n",
      "\n",
      "loss before training is 0.010231375478002092 -- epoch number 386\n",
      "\n",
      "\n",
      "loss before training is 0.010203968465067461 -- epoch number 387\n",
      "\n",
      "\n",
      "loss before training is 0.010176706913926983 -- epoch number 388\n",
      "\n",
      "\n",
      "loss before training is 0.010149589673521368 -- epoch number 389\n",
      "\n",
      "\n",
      "loss before training is 0.010122615604881572 -- epoch number 390\n",
      "\n",
      "\n",
      "loss before training is 0.010095783580970446 -- epoch number 391\n",
      "\n",
      "\n",
      "loss before training is 0.010069092486528132 -- epoch number 392\n",
      "\n",
      "\n",
      "loss before training is 0.010042541217917639 -- epoch number 393\n",
      "\n",
      "\n",
      "loss before training is 0.010016128682974749 -- epoch number 394\n",
      "\n",
      "\n",
      "loss before training is 0.00998985380085876 -- epoch number 395\n",
      "\n",
      "\n",
      "loss before training is 0.009963715501906986 -- epoch number 396\n",
      "\n",
      "\n",
      "loss before training is 0.009937712727490557 -- epoch number 397\n",
      "\n",
      "\n",
      "loss before training is 0.009911844429871947 -- epoch number 398\n",
      "\n",
      "\n",
      "loss before training is 0.009886109572066152 -- epoch number 399\n",
      "\n",
      "\n",
      "loss before training is 0.009860507127703491 -- epoch number 400\n",
      "\n",
      "\n",
      "loss before training is 0.009835036080893237 -- epoch number 401\n",
      "\n",
      "\n",
      "loss before training is 0.009809695426091352 -- epoch number 402\n",
      "\n",
      "\n",
      "loss before training is 0.009784484167968472 -- epoch number 403\n",
      "\n",
      "\n",
      "loss before training is 0.009759401321281114 -- epoch number 404\n",
      "\n",
      "\n",
      "loss before training is 0.00973444591074413 -- epoch number 405\n",
      "\n",
      "\n",
      "loss before training is 0.009709616970905815 -- epoch number 406\n",
      "\n",
      "\n",
      "loss before training is 0.009684913546023377 -- epoch number 407\n",
      "\n",
      "\n",
      "loss before training is 0.009660334689942509 -- epoch number 408\n",
      "\n",
      "\n",
      "loss before training is 0.009635879465977208 -- epoch number 409\n",
      "\n",
      "\n",
      "loss before training is 0.009611546946790553 -- epoch number 410\n",
      "\n",
      "\n",
      "loss before training is 0.009587336214280562 -- epoch number 411\n",
      "\n",
      "\n",
      "loss before training is 0.009563246359464183 -- epoch number 412\n",
      "\n",
      "\n",
      "loss before training is 0.009539276482364476 -- epoch number 413\n",
      "\n",
      "\n",
      "loss before training is 0.009515425691900396 -- epoch number 414\n",
      "\n",
      "\n",
      "loss before training is 0.009491693105776185 -- epoch number 415\n",
      "\n",
      "\n",
      "loss before training is 0.009468077850374384 -- epoch number 416\n",
      "\n",
      "\n",
      "loss before training is 0.009444579060649097 -- epoch number 417\n",
      "\n",
      "\n",
      "loss before training is 0.009421195880020876 -- epoch number 418\n",
      "\n",
      "\n",
      "loss before training is 0.009397927460274324 -- epoch number 419\n",
      "\n",
      "\n",
      "loss before training is 0.009374772961455405 -- epoch number 420\n",
      "\n",
      "\n",
      "loss before training is 0.009351731551772144 -- epoch number 421\n",
      "\n",
      "\n",
      "loss before training is 0.009328802407495132 -- epoch number 422\n",
      "\n",
      "\n",
      "loss before training is 0.009305984712860555 -- epoch number 423\n",
      "\n",
      "\n",
      "loss before training is 0.009283277659974349 -- epoch number 424\n",
      "\n",
      "\n",
      "loss before training is 0.00926068044871651 -- epoch number 425\n",
      "\n",
      "\n",
      "loss before training is 0.009238192286650154 -- epoch number 426\n",
      "\n",
      "\n",
      "loss before training is 0.009215812388927226 -- epoch number 427\n",
      "\n",
      "\n",
      "loss before training is 0.00919353997819907 -- epoch number 428\n",
      "\n",
      "\n",
      "loss before training is 0.009171374284527932 -- epoch number 429\n",
      "\n",
      "\n",
      "loss before training is 0.009149314545296796 -- epoch number 430\n",
      "\n",
      "\n",
      "loss before training is 0.009127360005125313 -- epoch number 431\n",
      "\n",
      "\n",
      "loss before training is 0.009105509915782045 -- epoch number 432\n",
      "\n",
      "\n",
      "loss before training is 0.009083763536101583 -- epoch number 433\n",
      "\n",
      "\n",
      "loss before training is 0.009062120131900428 -- epoch number 434\n",
      "\n",
      "\n",
      "loss before training is 0.009040578975895941 -- epoch number 435\n",
      "\n",
      "\n",
      "loss before training is 0.009019139347625101 -- epoch number 436\n",
      "\n",
      "\n",
      "loss before training is 0.008997800533364502 -- epoch number 437\n",
      "\n",
      "\n",
      "loss before training is 0.008976561826052745 -- epoch number 438\n",
      "\n",
      "\n",
      "loss before training is 0.008955422525212179 -- epoch number 439\n",
      "\n",
      "\n",
      "loss before training is 0.008934381936872786 -- epoch number 440\n",
      "\n",
      "\n",
      "loss before training is 0.008913439373496554 -- epoch number 441\n",
      "\n",
      "\n",
      "loss before training is 0.008892594153904096 -- epoch number 442\n",
      "\n",
      "\n",
      "loss before training is 0.008871845603200637 -- epoch number 443\n",
      "\n",
      "\n",
      "loss before training is 0.008851193052703469 -- epoch number 444\n",
      "\n",
      "\n",
      "loss before training is 0.00883063583987178 -- epoch number 445\n",
      "\n",
      "\n",
      "loss before training is 0.008810173308235619 -- epoch number 446\n",
      "\n",
      "\n",
      "loss before training is 0.008789804807327004 -- epoch number 447\n",
      "\n",
      "\n",
      "loss before training is 0.008769529692610712 -- epoch number 448\n",
      "\n",
      "\n",
      "loss before training is 0.008749347325418003 -- epoch number 449\n",
      "\n",
      "\n",
      "loss before training is 0.008729257072879816 -- epoch number 450\n",
      "\n",
      "\n",
      "loss before training is 0.008709258307860191 -- epoch number 451\n",
      "\n",
      "\n",
      "loss before training is 0.008689350408892973 -- epoch number 452\n",
      "\n",
      "\n",
      "loss before training is 0.008669532760116958 -- epoch number 453\n",
      "\n",
      "\n",
      "loss before training is 0.008649804751213526 -- epoch number 454\n",
      "\n",
      "\n",
      "loss before training is 0.008630165777344071 -- epoch number 455\n",
      "\n",
      "\n",
      "loss before training is 0.00861061523908845 -- epoch number 456\n",
      "\n",
      "\n",
      "loss before training is 0.008591152542385813 -- epoch number 457\n",
      "\n",
      "\n",
      "loss before training is 0.008571777098473416 -- epoch number 458\n",
      "\n",
      "\n",
      "loss before training is 0.008552488323828053 -- epoch number 459\n",
      "\n",
      "\n",
      "loss before training is 0.00853328564010916 -- epoch number 460\n",
      "\n",
      "\n",
      "loss before training is 0.008514168474099823 -- epoch number 461\n",
      "\n",
      "\n",
      "loss before training is 0.00849513625765149 -- epoch number 462\n",
      "\n",
      "\n",
      "loss before training is 0.008476188427627146 -- epoch number 463\n",
      "\n",
      "\n",
      "loss before training is 0.008457324425847047 -- epoch number 464\n",
      "\n",
      "\n",
      "loss before training is 0.008438543699034065 -- epoch number 465\n",
      "\n",
      "\n",
      "loss before training is 0.008419845698759794 -- epoch number 466\n",
      "\n",
      "\n",
      "loss before training is 0.008401229881391923 -- epoch number 467\n",
      "\n",
      "\n",
      "loss before training is 0.00838269570804185 -- epoch number 468\n",
      "\n",
      "\n",
      "loss before training is 0.0083642426445133 -- epoch number 469\n",
      "\n",
      "\n",
      "loss before training is 0.0083458701612512 -- epoch number 470\n",
      "\n",
      "\n",
      "loss before training is 0.008327577733291338 -- epoch number 471\n",
      "\n",
      "\n",
      "loss before training is 0.00830936484021117 -- epoch number 472\n",
      "\n",
      "\n",
      "loss before training is 0.0082912309660804 -- epoch number 473\n",
      "\n",
      "\n",
      "loss before training is 0.0082731755994136 -- epoch number 474\n",
      "\n",
      "\n",
      "loss before training is 0.008255198233120596 -- epoch number 475\n",
      "\n",
      "\n",
      "loss before training is 0.008237298364461921 -- epoch number 476\n",
      "\n",
      "\n",
      "loss before training is 0.008219475495000114 -- epoch number 477\n",
      "\n",
      "\n",
      "loss before training is 0.008201729130555412 -- epoch number 478\n",
      "\n",
      "\n",
      "loss before training is 0.00818405878115888 -- epoch number 479\n",
      "\n",
      "\n",
      "loss before training is 0.008166463961009921 -- epoch number 480\n",
      "\n",
      "\n",
      "loss before training is 0.008148944188429753 -- epoch number 481\n",
      "\n",
      "\n",
      "loss before training is 0.008131498985819278 -- epoch number 482\n",
      "\n",
      "\n",
      "loss before training is 0.008114127879615613 -- epoch number 483\n",
      "\n",
      "\n",
      "loss before training is 0.008096830400249421 -- epoch number 484\n",
      "\n",
      "\n",
      "loss before training is 0.008079606082103587 -- epoch number 485\n",
      "\n",
      "\n",
      "loss before training is 0.008062454463470347 -- epoch number 486\n",
      "\n",
      "\n",
      "loss before training is 0.008045375086513007 -- epoch number 487\n",
      "\n",
      "\n",
      "loss before training is 0.008028367497222424 -- epoch number 488\n",
      "\n",
      "\n",
      "loss before training is 0.008011431245379196 -- epoch number 489\n",
      "\n",
      "\n",
      "loss before training is 0.0079945658845134 -- epoch number 490\n",
      "\n",
      "\n",
      "loss before training is 0.007977770971866256 -- epoch number 491\n",
      "\n",
      "\n",
      "loss before training is 0.007961046068350542 -- epoch number 492\n",
      "\n",
      "\n",
      "loss before training is 0.007944390738515078 -- epoch number 493\n",
      "\n",
      "\n",
      "loss before training is 0.007927804550504059 -- epoch number 494\n",
      "\n",
      "\n",
      "loss before training is 0.007911287076022093 -- epoch number 495\n",
      "\n",
      "\n",
      "loss before training is 0.007894837890298033 -- epoch number 496\n",
      "\n",
      "\n",
      "loss before training is 0.007878456572046137 -- epoch number 497\n",
      "\n",
      "\n",
      "loss before training is 0.0078621427034337 -- epoch number 498\n",
      "\n",
      "\n",
      "loss before training is 0.007845895870044249 -- epoch number 499\n",
      "\n",
      "\n",
      "loss before training is 0.00782971566084241 -- epoch number 500\n",
      "\n",
      "\n",
      "loss before training is 0.0078136016681399 -- epoch number 501\n",
      "\n",
      "\n",
      "loss before training is 0.007797553487562545 -- epoch number 502\n",
      "\n",
      "\n",
      "loss before training is 0.007781570718014501 -- epoch number 503\n",
      "\n",
      "\n",
      "loss before training is 0.0077656529616472935 -- epoch number 504\n",
      "\n",
      "\n",
      "loss before training is 0.007749799823826073 -- epoch number 505\n",
      "\n",
      "\n",
      "loss before training is 0.0077340109130973325 -- epoch number 506\n",
      "\n",
      "\n",
      "loss before training is 0.007718285841157072 -- epoch number 507\n",
      "\n",
      "\n",
      "loss before training is 0.007702624222818872 -- epoch number 508\n",
      "\n",
      "\n",
      "loss before training is 0.007687025675983748 -- epoch number 509\n",
      "\n",
      "\n",
      "loss before training is 0.0076714898216079085 -- epoch number 510\n",
      "\n",
      "\n",
      "loss before training is 0.0076560162836731786 -- epoch number 511\n",
      "\n",
      "\n",
      "loss before training is 0.007640604689157008 -- epoch number 512\n",
      "\n",
      "\n",
      "loss before training is 0.007625254668002132 -- epoch number 513\n",
      "\n",
      "\n",
      "loss before training is 0.007609965853087595 -- epoch number 514\n",
      "\n",
      "\n",
      "loss before training is 0.007594737880199324 -- epoch number 515\n",
      "\n",
      "\n",
      "loss before training is 0.007579570388002615 -- epoch number 516\n",
      "\n",
      "\n",
      "loss before training is 0.007564463018012051 -- epoch number 517\n",
      "\n",
      "\n",
      "loss before training is 0.00754941541456445 -- epoch number 518\n",
      "\n",
      "\n",
      "loss before training is 0.007534427224792152 -- epoch number 519\n",
      "\n",
      "\n",
      "loss before training is 0.0075194980985930655 -- epoch number 520\n",
      "\n",
      "\n",
      "loss before training is 0.007504627688606324 -- epoch number 521\n",
      "\n",
      "\n",
      "loss before training is 0.007489815650183681 -- epoch number 522\n",
      "\n",
      "\n",
      "loss before training is 0.007475061641364956 -- epoch number 523\n",
      "\n",
      "\n",
      "loss before training is 0.0074603653228488866 -- epoch number 524\n",
      "\n",
      "\n",
      "loss before training is 0.00744572635797104 -- epoch number 525\n",
      "\n",
      "\n",
      "loss before training is 0.007431144412675573 -- epoch number 526\n",
      "\n",
      "\n",
      "loss before training is 0.007416619155491372 -- epoch number 527\n",
      "\n",
      "\n",
      "loss before training is 0.00740215025750661 -- epoch number 528\n",
      "\n",
      "\n",
      "loss before training is 0.007387737392344791 -- epoch number 529\n",
      "\n",
      "\n",
      "loss before training is 0.007373380236138428 -- epoch number 530\n",
      "\n",
      "\n",
      "loss before training is 0.007359078467507768 -- epoch number 531\n",
      "\n",
      "\n",
      "loss before training is 0.007344831767535279 -- epoch number 532\n",
      "\n",
      "\n",
      "loss before training is 0.00733063981974281 -- epoch number 533\n",
      "\n",
      "\n",
      "loss before training is 0.007316502310067097 -- epoch number 534\n",
      "\n",
      "\n",
      "loss before training is 0.007302418926839173 -- epoch number 535\n",
      "\n",
      "\n",
      "loss before training is 0.007288389360758645 -- epoch number 536\n",
      "\n",
      "\n",
      "loss before training is 0.007274413304873794 -- epoch number 537\n",
      "\n",
      "\n",
      "loss before training is 0.007260490454558767 -- epoch number 538\n",
      "\n",
      "\n",
      "loss before training is 0.007246620507489989 -- epoch number 539\n",
      "\n",
      "\n",
      "loss before training is 0.007232803163626504 -- epoch number 540\n",
      "\n",
      "\n",
      "loss before training is 0.00721903812518796 -- epoch number 541\n",
      "\n",
      "\n",
      "loss before training is 0.007205325096632605 -- epoch number 542\n",
      "\n",
      "\n",
      "loss before training is 0.007191663784636853 -- epoch number 543\n",
      "\n",
      "\n",
      "loss before training is 0.007178053898074628 -- epoch number 544\n",
      "\n",
      "\n",
      "loss before training is 0.007164495147997495 -- epoch number 545\n",
      "\n",
      "\n",
      "loss before training is 0.007150987247611894 -- epoch number 546\n",
      "\n",
      "\n",
      "loss before training is 0.0071375299122627385 -- epoch number 547\n",
      "\n",
      "\n",
      "loss before training is 0.0071241228594105515 -- epoch number 548\n",
      "\n",
      "\n",
      "loss before training is 0.007110765808613506 -- epoch number 549\n",
      "\n",
      "\n",
      "loss before training is 0.00709745848150691 -- epoch number 550\n",
      "\n",
      "\n",
      "loss before training is 0.007084200601784708 -- epoch number 551\n",
      "\n",
      "\n",
      "loss before training is 0.0070709918951811996 -- epoch number 552\n",
      "\n",
      "\n",
      "loss before training is 0.007057832089450316 -- epoch number 553\n",
      "\n",
      "\n",
      "loss before training is 0.007044720914349248 -- epoch number 554\n",
      "\n",
      "\n",
      "loss before training is 0.0070316581016182855 -- epoch number 555\n",
      "\n",
      "\n",
      "loss before training is 0.0070186433849639 -- epoch number 556\n",
      "\n",
      "\n",
      "loss before training is 0.007005676500040261 -- epoch number 557\n",
      "\n",
      "\n",
      "loss before training is 0.006992757184431434 -- epoch number 558\n",
      "\n",
      "\n",
      "loss before training is 0.006979885177634696 -- epoch number 559\n",
      "\n",
      "\n",
      "loss before training is 0.0069670602210410585 -- epoch number 560\n",
      "\n",
      "\n",
      "loss before training is 0.006954282057920714 -- epoch number 561\n",
      "\n",
      "\n",
      "loss before training is 0.006941550433403795 -- epoch number 562\n",
      "\n",
      "\n",
      "loss before training is 0.006928865094465598 -- epoch number 563\n",
      "\n",
      "\n",
      "loss before training is 0.006916225789908131 -- epoch number 564\n",
      "\n",
      "\n",
      "loss before training is 0.006903632270344565 -- epoch number 565\n",
      "\n",
      "\n",
      "loss before training is 0.006891084288183357 -- epoch number 566\n",
      "\n",
      "\n",
      "loss before training is 0.006878581597610921 -- epoch number 567\n",
      "\n",
      "\n",
      "loss before training is 0.00686612395457687 -- epoch number 568\n",
      "\n",
      "\n",
      "loss before training is 0.0068537111167772564 -- epoch number 569\n",
      "\n",
      "\n",
      "loss before training is 0.006841342843640604 -- epoch number 570\n",
      "\n",
      "\n",
      "loss before training is 0.006829018896310476 -- epoch number 571\n",
      "\n",
      "\n",
      "loss before training is 0.006816739037631411 -- epoch number 572\n",
      "\n",
      "\n",
      "loss before training is 0.006804503032133723 -- epoch number 573\n",
      "\n",
      "\n",
      "loss before training is 0.006792310646018664 -- epoch number 574\n",
      "\n",
      "\n",
      "loss before training is 0.006780161647142788 -- epoch number 575\n",
      "\n",
      "\n",
      "loss before training is 0.006768055805004898 -- epoch number 576\n",
      "\n",
      "\n",
      "loss before training is 0.0067559928907291915 -- epoch number 577\n",
      "\n",
      "\n",
      "loss before training is 0.006743972677054111 -- epoch number 578\n",
      "\n",
      "\n",
      "loss before training is 0.006731994938315161 -- epoch number 579\n",
      "\n",
      "\n",
      "loss before training is 0.006720059450433315 -- epoch number 580\n",
      "\n",
      "\n",
      "loss before training is 0.006708165990899071 -- epoch number 581\n",
      "\n",
      "\n",
      "loss before training is 0.006696314338760071 -- epoch number 582\n",
      "\n",
      "\n",
      "loss before training is 0.006684504274608078 -- epoch number 583\n",
      "\n",
      "\n",
      "loss before training is 0.0066727355805632485 -- epoch number 584\n",
      "\n",
      "\n",
      "loss before training is 0.006661008040262887 -- epoch number 585\n",
      "\n",
      "\n",
      "loss before training is 0.0066493214388474164 -- epoch number 586\n",
      "\n",
      "\n",
      "loss before training is 0.0066376755629482375 -- epoch number 587\n",
      "\n",
      "\n",
      "loss before training is 0.006626070200673478 -- epoch number 588\n",
      "\n",
      "\n",
      "loss before training is 0.006614505141596307 -- epoch number 589\n",
      "\n",
      "\n",
      "loss before training is 0.006602980176741466 -- epoch number 590\n",
      "\n",
      "\n",
      "loss before training is 0.006591495098574263 -- epoch number 591\n",
      "\n",
      "\n",
      "loss before training is 0.006580049700986214 -- epoch number 592\n",
      "\n",
      "\n",
      "loss before training is 0.006568643779284598 -- epoch number 593\n",
      "\n",
      "\n",
      "loss before training is 0.006557277130178771 -- epoch number 594\n",
      "\n",
      "\n",
      "loss before training is 0.006545949551769841 -- epoch number 595\n",
      "\n",
      "\n",
      "loss before training is 0.006534660843537323 -- epoch number 596\n",
      "\n",
      "\n",
      "loss before training is 0.006523410806328699 -- epoch number 597\n",
      "\n",
      "\n",
      "loss before training is 0.006512199242346193 -- epoch number 598\n",
      "\n",
      "\n",
      "loss before training is 0.006501025955137122 -- epoch number 599\n",
      "\n",
      "\n",
      "loss before training is 0.006489890749580889 -- epoch number 600\n",
      "\n",
      "\n",
      "loss before training is 0.006478793431879006 -- epoch number 601\n",
      "\n",
      "\n",
      "loss before training is 0.006467733809542991 -- epoch number 602\n",
      "\n",
      "\n",
      "loss before training is 0.006456711691383717 -- epoch number 603\n",
      "\n",
      "\n",
      "loss before training is 0.0064457268875003195 -- epoch number 604\n",
      "\n",
      "\n",
      "loss before training is 0.00643477920927022 -- epoch number 605\n",
      "\n",
      "\n",
      "loss before training is 0.006423868469336921 -- epoch number 606\n",
      "\n",
      "\n",
      "loss before training is 0.006412994481600258 -- epoch number 607\n",
      "\n",
      "\n",
      "loss before training is 0.006402157061206205 -- epoch number 608\n",
      "\n",
      "\n",
      "loss before training is 0.006391356024535791 -- epoch number 609\n",
      "\n",
      "\n",
      "loss before training is 0.006380591189195243 -- epoch number 610\n",
      "\n",
      "\n",
      "loss before training is 0.006369862374006027 -- epoch number 611\n",
      "\n",
      "\n",
      "loss before training is 0.006359169398993429 -- epoch number 612\n",
      "\n",
      "\n",
      "loss before training is 0.00634851208537838 -- epoch number 613\n",
      "\n",
      "\n",
      "loss before training is 0.006337890255566831 -- epoch number 614\n",
      "\n",
      "\n",
      "loss before training is 0.00632730373313901 -- epoch number 615\n",
      "\n",
      "\n",
      "loss before training is 0.0063167523428417 -- epoch number 616\n",
      "\n",
      "\n",
      "loss before training is 0.006306235910576496 -- epoch number 617\n",
      "\n",
      "\n",
      "loss before training is 0.006295754263391977 -- epoch number 618\n",
      "\n",
      "\n",
      "loss before training is 0.006285307229473533 -- epoch number 619\n",
      "\n",
      "\n",
      "loss before training is 0.0062748946381341875 -- epoch number 620\n",
      "\n",
      "\n",
      "loss before training is 0.006264516319805328 -- epoch number 621\n",
      "\n",
      "\n",
      "loss before training is 0.006254172106027425 -- epoch number 622\n",
      "\n",
      "\n",
      "loss before training is 0.0062438618294415405 -- epoch number 623\n",
      "\n",
      "\n",
      "loss before training is 0.006233585323779715 -- epoch number 624\n",
      "\n",
      "\n",
      "loss before training is 0.006223342423856591 -- epoch number 625\n",
      "\n",
      "\n",
      "loss before training is 0.00621313296555992 -- epoch number 626\n",
      "\n",
      "\n",
      "loss before training is 0.006202956785843409 -- epoch number 627\n",
      "\n",
      "\n",
      "loss before training is 0.006192813722715784 -- epoch number 628\n",
      "\n",
      "\n",
      "loss before training is 0.006182703615234418 -- epoch number 629\n",
      "\n",
      "\n",
      "loss before training is 0.006172626303495851 -- epoch number 630\n",
      "\n",
      "\n",
      "loss before training is 0.006162581628627521 -- epoch number 631\n",
      "\n",
      "\n",
      "loss before training is 0.006152569432779402 -- epoch number 632\n",
      "\n",
      "\n",
      "loss before training is 0.006142589559116299 -- epoch number 633\n",
      "\n",
      "\n",
      "loss before training is 0.006132641851808258 -- epoch number 634\n",
      "\n",
      "\n",
      "loss before training is 0.006122726156025658 -- epoch number 635\n",
      "\n",
      "\n",
      "loss before training is 0.0061128423179270495 -- epoch number 636\n",
      "\n",
      "\n",
      "loss before training is 0.006102990184655258 -- epoch number 637\n",
      "\n",
      "\n",
      "loss before training is 0.0060931696043257854 -- epoch number 638\n",
      "\n",
      "\n",
      "loss before training is 0.006083380426022912 -- epoch number 639\n",
      "\n",
      "\n",
      "loss before training is 0.006073622499788655 -- epoch number 640\n",
      "\n",
      "\n",
      "loss before training is 0.006063895676617654 -- epoch number 641\n",
      "\n",
      "\n",
      "loss before training is 0.00605419980844758 -- epoch number 642\n",
      "\n",
      "\n",
      "loss before training is 0.006044534748153907 -- epoch number 643\n",
      "\n",
      "\n",
      "loss before training is 0.0060349003495401 -- epoch number 644\n",
      "\n",
      "\n",
      "loss before training is 0.006025296467332621 -- epoch number 645\n",
      "\n",
      "\n",
      "loss before training is 0.006015722957171557 -- epoch number 646\n",
      "\n",
      "\n",
      "loss before training is 0.006006179675605629 -- epoch number 647\n",
      "\n",
      "\n",
      "loss before training is 0.005996666480082829 -- epoch number 648\n",
      "\n",
      "\n",
      "loss before training is 0.005987183228945086 -- epoch number 649\n",
      "\n",
      "\n",
      "loss before training is 0.005977729781420478 -- epoch number 650\n",
      "\n",
      "\n",
      "loss before training is 0.005968305997616776 -- epoch number 651\n",
      "\n",
      "\n",
      "loss before training is 0.005958911738513995 -- epoch number 652\n",
      "\n",
      "\n",
      "loss before training is 0.005949546865957944 -- epoch number 653\n",
      "\n",
      "\n",
      "loss before training is 0.005940211242654002 -- epoch number 654\n",
      "\n",
      "\n",
      "loss before training is 0.005930904732159444 -- epoch number 655\n",
      "\n",
      "\n",
      "loss before training is 0.005921627198877443 -- epoch number 656\n",
      "\n",
      "\n",
      "loss before training is 0.005912378508050847 -- epoch number 657\n",
      "\n",
      "\n",
      "loss before training is 0.005903158525754397 -- epoch number 658\n",
      "\n",
      "\n",
      "loss before training is 0.005893967118890742 -- epoch number 659\n",
      "\n",
      "\n",
      "loss before training is 0.0058848041551808694 -- epoch number 660\n",
      "\n",
      "\n",
      "loss before training is 0.005875669503160903 -- epoch number 661\n",
      "\n",
      "\n",
      "loss before training is 0.00586656303217354 -- epoch number 662\n",
      "\n",
      "\n",
      "loss before training is 0.005857484612363626 -- epoch number 663\n",
      "\n",
      "\n",
      "loss before training is 0.005848434114669815 -- epoch number 664\n",
      "\n",
      "\n",
      "loss before training is 0.005839411410821593 -- epoch number 665\n",
      "\n",
      "\n",
      "loss before training is 0.00583041637333039 -- epoch number 666\n",
      "\n",
      "\n",
      "loss before training is 0.005821448875485036 -- epoch number 667\n",
      "\n",
      "\n",
      "loss before training is 0.005812508791346 -- epoch number 668\n",
      "\n",
      "\n",
      "loss before training is 0.0058035959957384 -- epoch number 669\n",
      "\n",
      "\n",
      "loss before training is 0.005794710364247907 -- epoch number 670\n",
      "\n",
      "\n",
      "loss before training is 0.0057858517732129805 -- epoch number 671\n",
      "\n",
      "\n",
      "loss before training is 0.0057770200997210005 -- epoch number 672\n",
      "\n",
      "\n",
      "loss before training is 0.005768215221601727 -- epoch number 673\n",
      "\n",
      "\n",
      "loss before training is 0.005759437017421313 -- epoch number 674\n",
      "\n",
      "\n",
      "loss before training is 0.005750685366478002 -- epoch number 675\n",
      "\n",
      "\n",
      "loss before training is 0.005741960148795471 -- epoch number 676\n",
      "\n",
      "\n",
      "loss before training is 0.005733261245117969 -- epoch number 677\n",
      "\n",
      "\n",
      "loss before training is 0.005724588536904893 -- epoch number 678\n",
      "\n",
      "\n",
      "loss before training is 0.005715941906325032 -- epoch number 679\n",
      "\n",
      "\n",
      "loss before training is 0.00570732123625215 -- epoch number 680\n",
      "\n",
      "\n",
      "loss before training is 0.005698726410258339 -- epoch number 681\n",
      "\n",
      "\n",
      "loss before training is 0.005690157312610273 -- epoch number 682\n",
      "\n",
      "\n",
      "loss before training is 0.005681613828263566 -- epoch number 683\n",
      "\n",
      "\n",
      "loss before training is 0.005673095842856906 -- epoch number 684\n",
      "\n",
      "\n",
      "loss before training is 0.00566460324270776 -- epoch number 685\n",
      "\n",
      "\n",
      "loss before training is 0.005656135914807839 -- epoch number 686\n",
      "\n",
      "\n",
      "loss before training is 0.005647693746816578 -- epoch number 687\n",
      "\n",
      "\n",
      "loss before training is 0.005639276627057496 -- epoch number 688\n",
      "\n",
      "\n",
      "loss before training is 0.005630884444513232 -- epoch number 689\n",
      "\n",
      "\n",
      "loss before training is 0.0056225170888196865 -- epoch number 690\n",
      "\n",
      "\n",
      "loss before training is 0.005614174450263061 -- epoch number 691\n",
      "\n",
      "\n",
      "loss before training is 0.005605856419772432 -- epoch number 692\n",
      "\n",
      "\n",
      "loss before training is 0.005597562888917473 -- epoch number 693\n",
      "\n",
      "\n",
      "loss before training is 0.005589293749902921 -- epoch number 694\n",
      "\n",
      "\n",
      "loss before training is 0.0055810488955636214 -- epoch number 695\n",
      "\n",
      "\n",
      "loss before training is 0.005572828219360336 -- epoch number 696\n",
      "\n",
      "\n",
      "loss before training is 0.005564631615374673 -- epoch number 697\n",
      "\n",
      "\n",
      "loss before training is 0.005556458978305575 -- epoch number 698\n",
      "\n",
      "\n",
      "loss before training is 0.005548310203463685 -- epoch number 699\n",
      "\n",
      "\n",
      "loss before training is 0.005540185186767503 -- epoch number 700\n",
      "\n",
      "\n",
      "loss before training is 0.0055320838247392016 -- epoch number 701\n",
      "\n",
      "\n",
      "loss before training is 0.005524006014499669 -- epoch number 702\n",
      "\n",
      "\n",
      "loss before training is 0.005515951653764667 -- epoch number 703\n",
      "\n",
      "\n",
      "loss before training is 0.005507920640840308 -- epoch number 704\n",
      "\n",
      "\n",
      "loss before training is 0.00549991287461889 -- epoch number 705\n",
      "\n",
      "\n",
      "loss before training is 0.005491928254574486 -- epoch number 706\n",
      "\n",
      "\n",
      "loss before training is 0.005483966680759774 -- epoch number 707\n",
      "\n",
      "\n",
      "loss before training is 0.005476028053799299 -- epoch number 708\n",
      "\n",
      "\n",
      "loss before training is 0.005468112274889306 -- epoch number 709\n",
      "\n",
      "\n",
      "loss before training is 0.005460219245790114 -- epoch number 710\n",
      "\n",
      "\n",
      "loss before training is 0.005452348868823383 -- epoch number 711\n",
      "\n",
      "\n",
      "loss before training is 0.005444501046869398 -- epoch number 712\n",
      "\n",
      "\n",
      "loss before training is 0.005436675683360547 -- epoch number 713\n",
      "\n",
      "\n",
      "loss before training is 0.005428872682279605 -- epoch number 714\n",
      "\n",
      "\n",
      "loss before training is 0.005421091948154665 -- epoch number 715\n",
      "\n",
      "\n",
      "loss before training is 0.005413333386055752 -- epoch number 716\n",
      "\n",
      "\n",
      "loss before training is 0.0054055969015905335 -- epoch number 717\n",
      "\n",
      "\n",
      "loss before training is 0.0053978824009011574 -- epoch number 718\n",
      "\n",
      "\n",
      "loss before training is 0.005390189790659965 -- epoch number 719\n",
      "\n",
      "\n",
      "loss before training is 0.0053825189780656564 -- epoch number 720\n",
      "\n",
      "\n",
      "loss before training is 0.005374869870840575 -- epoch number 721\n",
      "\n",
      "\n",
      "loss before training is 0.005367242377225638 -- epoch number 722\n",
      "\n",
      "\n",
      "loss before training is 0.005359636405977622 -- epoch number 723\n",
      "\n",
      "\n",
      "loss before training is 0.00535205186636544 -- epoch number 724\n",
      "\n",
      "\n",
      "loss before training is 0.005344488668165972 -- epoch number 725\n",
      "\n",
      "\n",
      "loss before training is 0.005336946721661459 -- epoch number 726\n",
      "\n",
      "\n",
      "loss before training is 0.005329425937635338 -- epoch number 727\n",
      "\n",
      "\n",
      "loss before training is 0.005321926227368404 -- epoch number 728\n",
      "\n",
      "\n",
      "loss before training is 0.005314447502636767 -- epoch number 729\n",
      "\n",
      "\n",
      "loss before training is 0.005306989675707019 -- epoch number 730\n",
      "\n",
      "\n",
      "loss before training is 0.005299552659332507 -- epoch number 731\n",
      "\n",
      "\n",
      "loss before training is 0.0052921363667520725 -- epoch number 732\n",
      "\n",
      "\n",
      "loss before training is 0.005284740711685106 -- epoch number 733\n",
      "\n",
      "\n",
      "loss before training is 0.0052773656083273815 -- epoch number 734\n",
      "\n",
      "\n",
      "loss before training is 0.005270010971350124 -- epoch number 735\n",
      "\n",
      "\n",
      "loss before training is 0.005262676715894737 -- epoch number 736\n",
      "\n",
      "\n",
      "loss before training is 0.005255362757570974 -- epoch number 737\n",
      "\n",
      "\n",
      "loss before training is 0.005248069012452334 -- epoch number 738\n",
      "\n",
      "\n",
      "loss before training is 0.005240795397074127 -- epoch number 739\n",
      "\n",
      "\n",
      "loss before training is 0.005233541828429538 -- epoch number 740\n",
      "\n",
      "\n",
      "loss before training is 0.005226308223966912 -- epoch number 741\n",
      "\n",
      "\n",
      "loss before training is 0.005219094501586371 -- epoch number 742\n",
      "\n",
      "\n",
      "loss before training is 0.005211900579636664 -- epoch number 743\n",
      "\n",
      "\n",
      "loss before training is 0.005204726376912562 -- epoch number 744\n",
      "\n",
      "\n",
      "loss before training is 0.005197571812651588 -- epoch number 745\n",
      "\n",
      "\n",
      "loss before training is 0.005190436806530645 -- epoch number 746\n",
      "\n",
      "\n",
      "loss before training is 0.005183321278663631 -- epoch number 747\n",
      "\n",
      "\n",
      "loss before training is 0.005176225149597733 -- epoch number 748\n",
      "\n",
      "\n",
      "loss before training is 0.0051691483403118335 -- epoch number 749\n",
      "\n",
      "\n",
      "loss before training is 0.005162090772211898 -- epoch number 750\n",
      "\n",
      "\n",
      "loss before training is 0.005155052367129167 -- epoch number 751\n",
      "\n",
      "\n",
      "loss before training is 0.005148033047316771 -- epoch number 752\n",
      "\n",
      "\n",
      "loss before training is 0.005141032735448034 -- epoch number 753\n",
      "\n",
      "\n",
      "loss before training is 0.00513405135461153 -- epoch number 754\n",
      "\n",
      "\n",
      "loss before training is 0.005127088828310718 -- epoch number 755\n",
      "\n",
      "\n",
      "loss before training is 0.005120145080458894 -- epoch number 756\n",
      "\n",
      "\n",
      "loss before training is 0.0051132200353781595 -- epoch number 757\n",
      "\n",
      "\n",
      "loss before training is 0.005106313617796041 -- epoch number 758\n",
      "\n",
      "\n",
      "loss before training is 0.005099425752842341 -- epoch number 759\n",
      "\n",
      "\n",
      "loss before training is 0.005092556366047658 -- epoch number 760\n",
      "\n",
      "\n",
      "loss before training is 0.00508570538333923 -- epoch number 761\n",
      "\n",
      "\n",
      "loss before training is 0.005078872731039238 -- epoch number 762\n",
      "\n",
      "\n",
      "loss before training is 0.00507205833586209 -- epoch number 763\n",
      "\n",
      "\n",
      "loss before training is 0.0050652621249113955 -- epoch number 764\n",
      "\n",
      "\n",
      "loss before training is 0.005058484025678256 -- epoch number 765\n",
      "\n",
      "\n",
      "loss before training is 0.0050517239660377794 -- epoch number 766\n",
      "\n",
      "\n",
      "loss before training is 0.005044981874246716 -- epoch number 767\n",
      "\n",
      "\n",
      "loss before training is 0.005038257678941199 -- epoch number 768\n",
      "\n",
      "\n",
      "loss before training is 0.00503155130913493 -- epoch number 769\n",
      "\n",
      "\n",
      "loss before training is 0.005024862694214361 -- epoch number 770\n",
      "\n",
      "\n",
      "loss before training is 0.005018191763939335 -- epoch number 771\n",
      "\n",
      "\n",
      "loss before training is 0.005011538448438045 -- epoch number 772\n",
      "\n",
      "\n",
      "loss before training is 0.0050049026782065555 -- epoch number 773\n",
      "\n",
      "\n",
      "loss before training is 0.004998284384104767 -- epoch number 774\n",
      "\n",
      "\n",
      "loss before training is 0.004991683497355163 -- epoch number 775\n",
      "\n",
      "\n",
      "loss before training is 0.004985099949539999 -- epoch number 776\n",
      "\n",
      "\n",
      "loss before training is 0.004978533672599153 -- epoch number 777\n",
      "\n",
      "\n",
      "loss before training is 0.004971984598827318 -- epoch number 778\n",
      "\n",
      "\n",
      "loss before training is 0.004965452660872637 -- epoch number 779\n",
      "\n",
      "\n",
      "loss before training is 0.0049589377917326665 -- epoch number 780\n",
      "\n",
      "\n",
      "loss before training is 0.004952439924754683 -- epoch number 781\n",
      "\n",
      "\n",
      "loss before training is 0.004945958993631203 -- epoch number 782\n",
      "\n",
      "\n",
      "loss before training is 0.004939494932398171 -- epoch number 783\n",
      "\n",
      "\n",
      "loss before training is 0.004933047675434271 -- epoch number 784\n",
      "\n",
      "\n",
      "loss before training is 0.004926617157456107 -- epoch number 785\n",
      "\n",
      "\n",
      "loss before training is 0.004920203313518734 -- epoch number 786\n",
      "\n",
      "\n",
      "loss before training is 0.004913806079011293 -- epoch number 787\n",
      "\n",
      "\n",
      "loss before training is 0.004907425389656313 -- epoch number 788\n",
      "\n",
      "\n",
      "loss before training is 0.004901061181506795 -- epoch number 789\n",
      "\n",
      "\n",
      "loss before training is 0.0048947133909441765 -- epoch number 790\n",
      "\n",
      "\n",
      "loss before training is 0.004888381954676753 -- epoch number 791\n",
      "\n",
      "\n",
      "loss before training is 0.0048820668097367586 -- epoch number 792\n",
      "\n",
      "\n",
      "loss before training is 0.004875767893479446 -- epoch number 793\n",
      "\n",
      "\n",
      "loss before training is 0.00486948514357939 -- epoch number 794\n",
      "\n",
      "\n",
      "loss before training is 0.004863218498030132 -- epoch number 795\n",
      "\n",
      "\n",
      "loss before training is 0.0048569678951410344 -- epoch number 796\n",
      "\n",
      "\n",
      "loss before training is 0.004850733273536035 -- epoch number 797\n",
      "\n",
      "\n",
      "loss before training is 0.004844514572150393 -- epoch number 798\n",
      "\n",
      "\n",
      "loss before training is 0.004838311730230555 -- epoch number 799\n",
      "\n",
      "\n",
      "loss before training is 0.004832124687330793 -- epoch number 800\n",
      "\n",
      "\n",
      "loss before training is 0.004825953383311284 -- epoch number 801\n",
      "\n",
      "\n",
      "loss before training is 0.0048197977583374265 -- epoch number 802\n",
      "\n",
      "\n",
      "loss before training is 0.004813657752876361 -- epoch number 803\n",
      "\n",
      "\n",
      "loss before training is 0.004807533307695724 -- epoch number 804\n",
      "\n",
      "\n",
      "loss before training is 0.004801424363862403 -- epoch number 805\n",
      "\n",
      "\n",
      "loss before training is 0.004795330862739396 -- epoch number 806\n",
      "\n",
      "\n",
      "loss before training is 0.00478925274598501 -- epoch number 807\n",
      "\n",
      "\n",
      "loss before training is 0.004783189955550502 -- epoch number 808\n",
      "\n",
      "\n",
      "loss before training is 0.0047771424336779415 -- epoch number 809\n",
      "\n",
      "\n",
      "loss before training is 0.004771110122899523 -- epoch number 810\n",
      "\n",
      "\n",
      "loss before training is 0.004765092966034317 -- epoch number 811\n",
      "\n",
      "\n",
      "loss before training is 0.004759090906187687 -- epoch number 812\n",
      "\n",
      "\n",
      "loss before training is 0.004753103886748714 -- epoch number 813\n",
      "\n",
      "\n",
      "loss before training is 0.00474713185138884 -- epoch number 814\n",
      "\n",
      "\n",
      "loss before training is 0.0047411747440601745 -- epoch number 815\n",
      "\n",
      "\n",
      "loss before training is 0.004735232508992689 -- epoch number 816\n",
      "\n",
      "\n",
      "loss before training is 0.004729305090694542 -- epoch number 817\n",
      "\n",
      "\n",
      "loss before training is 0.004723392433948482 -- epoch number 818\n",
      "\n",
      "\n",
      "loss before training is 0.0047174944838111734 -- epoch number 819\n",
      "\n",
      "\n",
      "loss before training is 0.00471161118561083 -- epoch number 820\n",
      "\n",
      "\n",
      "loss before training is 0.004705742484946308 -- epoch number 821\n",
      "\n",
      "\n",
      "loss before training is 0.0046998883276844145 -- epoch number 822\n",
      "\n",
      "\n",
      "loss before training is 0.004694048659959893 -- epoch number 823\n",
      "\n",
      "\n",
      "loss before training is 0.004688223428171278 -- epoch number 824\n",
      "\n",
      "\n",
      "loss before training is 0.0046824125789823295 -- epoch number 825\n",
      "\n",
      "\n",
      "loss before training is 0.004676616059317782 -- epoch number 826\n",
      "\n",
      "\n",
      "loss before training is 0.004670833816362993 -- epoch number 827\n",
      "\n",
      "\n",
      "loss before training is 0.004665065797562141 -- epoch number 828\n",
      "\n",
      "\n",
      "loss before training is 0.004659311950616986 -- epoch number 829\n",
      "\n",
      "\n",
      "loss before training is 0.004653572223484403 -- epoch number 830\n",
      "\n",
      "\n",
      "loss before training is 0.0046478465643756935 -- epoch number 831\n",
      "\n",
      "\n",
      "loss before training is 0.004642134921754901 -- epoch number 832\n",
      "\n",
      "\n",
      "loss before training is 0.004636437244336563 -- epoch number 833\n",
      "\n",
      "\n",
      "loss before training is 0.0046307534810852554 -- epoch number 834\n",
      "\n",
      "\n",
      "loss before training is 0.00462508358121323 -- epoch number 835\n",
      "\n",
      "\n",
      "loss before training is 0.004619427494179289 -- epoch number 836\n",
      "\n",
      "\n",
      "loss before training is 0.004613785169687321 -- epoch number 837\n",
      "\n",
      "\n",
      "loss before training is 0.0046081565576843895 -- epoch number 838\n",
      "\n",
      "\n",
      "loss before training is 0.004602541608359939 -- epoch number 839\n",
      "\n",
      "\n",
      "loss before training is 0.004596940272144219 -- epoch number 840\n",
      "\n",
      "\n",
      "loss before training is 0.004591352499705933 -- epoch number 841\n",
      "\n",
      "\n",
      "loss before training is 0.004585778241952105 -- epoch number 842\n",
      "\n",
      "\n",
      "loss before training is 0.004580217450025397 -- epoch number 843\n",
      "\n",
      "\n",
      "loss before training is 0.004574670075304208 -- epoch number 844\n",
      "\n",
      "\n",
      "loss before training is 0.004569136069399193 -- epoch number 845\n",
      "\n",
      "\n",
      "loss before training is 0.0045636153841542675 -- epoch number 846\n",
      "\n",
      "\n",
      "loss before training is 0.00455810797164324 -- epoch number 847\n",
      "\n",
      "\n",
      "loss before training is 0.004552613784169357 -- epoch number 848\n",
      "\n",
      "\n",
      "loss before training is 0.004547132774263835 -- epoch number 849\n",
      "\n",
      "\n",
      "loss before training is 0.004541664894684409 -- epoch number 850\n",
      "\n",
      "\n",
      "loss before training is 0.004536210098414081 -- epoch number 851\n",
      "\n",
      "\n",
      "loss before training is 0.004530768338659332 -- epoch number 852\n",
      "\n",
      "\n",
      "loss before training is 0.004525339568849882 -- epoch number 853\n",
      "\n",
      "\n",
      "loss before training is 0.004519923742636115 -- epoch number 854\n",
      "\n",
      "\n",
      "loss before training is 0.004514520813888511 -- epoch number 855\n",
      "\n",
      "\n",
      "loss before training is 0.0045091307366964 -- epoch number 856\n",
      "\n",
      "\n",
      "loss before training is 0.004503753465365621 -- epoch number 857\n",
      "\n",
      "\n",
      "loss before training is 0.00449838895441883 -- epoch number 858\n",
      "\n",
      "\n",
      "loss before training is 0.004493037158593159 -- epoch number 859\n",
      "\n",
      "\n",
      "loss before training is 0.004487698032839303 -- epoch number 860\n",
      "\n",
      "\n",
      "loss before training is 0.004482371532319955 -- epoch number 861\n",
      "\n",
      "\n",
      "loss before training is 0.004477057612409232 -- epoch number 862\n",
      "\n",
      "\n",
      "loss before training is 0.004471756228690547 -- epoch number 863\n",
      "\n",
      "\n",
      "loss before training is 0.004466467336955814 -- epoch number 864\n",
      "\n",
      "\n",
      "loss before training is 0.004461190893204774 -- epoch number 865\n",
      "\n",
      "\n",
      "loss before training is 0.004455926853642861 -- epoch number 866\n",
      "\n",
      "\n",
      "loss before training is 0.0044506751746804084 -- epoch number 867\n",
      "\n",
      "\n",
      "loss before training is 0.00444543581293153 -- epoch number 868\n",
      "\n",
      "\n",
      "loss before training is 0.00444020872521254 -- epoch number 869\n",
      "\n",
      "\n",
      "loss before training is 0.004434993868541727 -- epoch number 870\n",
      "\n",
      "\n",
      "loss before training is 0.004429791200136885 -- epoch number 871\n",
      "\n",
      "\n",
      "loss before training is 0.00442460067741508 -- epoch number 872\n",
      "\n",
      "\n",
      "loss before training is 0.004419422257990971 -- epoch number 873\n",
      "\n",
      "\n",
      "loss before training is 0.00441425589967646 -- epoch number 874\n",
      "\n",
      "\n",
      "loss before training is 0.0044091015604783455 -- epoch number 875\n",
      "\n",
      "\n",
      "loss before training is 0.00440395919859842 -- epoch number 876\n",
      "\n",
      "\n",
      "loss before training is 0.004398828772431229 -- epoch number 877\n",
      "\n",
      "\n",
      "loss before training is 0.00439371024056362 -- epoch number 878\n",
      "\n",
      "\n",
      "loss before training is 0.004388603561773835 -- epoch number 879\n",
      "\n",
      "\n",
      "loss before training is 0.0043835086950301675 -- epoch number 880\n",
      "\n",
      "\n",
      "loss before training is 0.004378425599489165 -- epoch number 881\n",
      "\n",
      "\n",
      "loss before training is 0.0043733542344955075 -- epoch number 882\n",
      "\n",
      "\n",
      "loss before training is 0.004368294559580889 -- epoch number 883\n",
      "\n",
      "\n",
      "loss before training is 0.0043632465344622135 -- epoch number 884\n",
      "\n",
      "\n",
      "loss before training is 0.0043582101190412625 -- epoch number 885\n",
      "\n",
      "\n",
      "loss before training is 0.004353185273403116 -- epoch number 886\n",
      "\n",
      "\n",
      "loss before training is 0.0043481719578154785 -- epoch number 887\n",
      "\n",
      "\n",
      "loss before training is 0.004343170132727331 -- epoch number 888\n",
      "\n",
      "\n",
      "loss before training is 0.004338179758768586 -- epoch number 889\n",
      "\n",
      "\n",
      "loss before training is 0.0043332007967478514 -- epoch number 890\n",
      "\n",
      "\n",
      "loss before training is 0.004328233207652529 -- epoch number 891\n",
      "\n",
      "\n",
      "loss before training is 0.0043232769526474705 -- epoch number 892\n",
      "\n",
      "\n",
      "loss before training is 0.004318331993073073 -- epoch number 893\n",
      "\n",
      "\n",
      "loss before training is 0.004313398290446496 -- epoch number 894\n",
      "\n",
      "\n",
      "loss before training is 0.004308475806457639 -- epoch number 895\n",
      "\n",
      "\n",
      "loss before training is 0.004303564502971029 -- epoch number 896\n",
      "\n",
      "\n",
      "loss before training is 0.004298664342023244 -- epoch number 897\n",
      "\n",
      "\n",
      "loss before training is 0.004293775285821795 -- epoch number 898\n",
      "\n",
      "\n",
      "loss before training is 0.0042888972967452255 -- epoch number 899\n",
      "\n",
      "\n",
      "loss before training is 0.004284030337341544 -- epoch number 900\n",
      "\n",
      "\n",
      "loss before training is 0.004279174370326877 -- epoch number 901\n",
      "\n",
      "\n",
      "loss before training is 0.004274329358585236 -- epoch number 902\n",
      "\n",
      "\n",
      "loss before training is 0.0042694952651672865 -- epoch number 903\n",
      "\n",
      "\n",
      "loss before training is 0.004264672053289445 -- epoch number 904\n",
      "\n",
      "\n",
      "loss before training is 0.0042598596863328685 -- epoch number 905\n",
      "\n",
      "\n",
      "loss before training is 0.004255058127842668 -- epoch number 906\n",
      "\n",
      "\n",
      "loss before training is 0.004250267341526781 -- epoch number 907\n",
      "\n",
      "\n",
      "loss before training is 0.004245487291255189 -- epoch number 908\n",
      "\n",
      "\n",
      "loss before training is 0.004240717941059238 -- epoch number 909\n",
      "\n",
      "\n",
      "loss before training is 0.004235959255130289 -- epoch number 910\n",
      "\n",
      "\n",
      "loss before training is 0.004231211197819162 -- epoch number 911\n",
      "\n",
      "\n",
      "loss before training is 0.004226473733635449 -- epoch number 912\n",
      "\n",
      "\n",
      "loss before training is 0.004221746827245843 -- epoch number 913\n",
      "\n",
      "\n",
      "loss before training is 0.004217030443473903 -- epoch number 914\n",
      "\n",
      "\n",
      "loss before training is 0.004212324547299154 -- epoch number 915\n",
      "\n",
      "\n",
      "loss before training is 0.004207629103856303 -- epoch number 916\n",
      "\n",
      "\n",
      "loss before training is 0.004202944078433668 -- epoch number 917\n",
      "\n",
      "\n",
      "loss before training is 0.004198269436473728 -- epoch number 918\n",
      "\n",
      "\n",
      "loss before training is 0.004193605143570218 -- epoch number 919\n",
      "\n",
      "\n",
      "loss before training is 0.004188951165469795 -- epoch number 920\n",
      "\n",
      "\n",
      "loss before training is 0.004184307468068685 -- epoch number 921\n",
      "\n",
      "\n",
      "loss before training is 0.004179674017414015 -- epoch number 922\n",
      "\n",
      "\n",
      "loss before training is 0.004175050779701575 -- epoch number 923\n",
      "\n",
      "\n",
      "loss before training is 0.004170437721275142 -- epoch number 924\n",
      "\n",
      "\n",
      "loss before training is 0.00416583480862681 -- epoch number 925\n",
      "\n",
      "\n",
      "loss before training is 0.004161242008394974 -- epoch number 926\n",
      "\n",
      "\n",
      "loss before training is 0.0041566592873635445 -- epoch number 927\n",
      "\n",
      "\n",
      "loss before training is 0.004152086612462163 -- epoch number 928\n",
      "\n",
      "\n",
      "loss before training is 0.00414752395076441 -- epoch number 929\n",
      "\n",
      "\n",
      "loss before training is 0.0041429712694873565 -- epoch number 930\n",
      "\n",
      "\n",
      "loss before training is 0.004138428535991107 -- epoch number 931\n",
      "\n",
      "\n",
      "loss before training is 0.004133895717777237 -- epoch number 932\n",
      "\n",
      "\n",
      "loss before training is 0.004129372782489339 -- epoch number 933\n",
      "\n",
      "\n",
      "loss before training is 0.004124859697910122 -- epoch number 934\n",
      "\n",
      "\n",
      "loss before training is 0.004120356431963518 -- epoch number 935\n",
      "\n",
      "\n",
      "loss before training is 0.00411586295271134 -- epoch number 936\n",
      "\n",
      "\n",
      "loss before training is 0.004111379228353711 -- epoch number 937\n",
      "\n",
      "\n",
      "loss before training is 0.004106905227228509 -- epoch number 938\n",
      "\n",
      "\n",
      "loss before training is 0.004102440917809906 -- epoch number 939\n",
      "\n",
      "\n",
      "loss before training is 0.004097986268708367 -- epoch number 940\n",
      "\n",
      "\n",
      "loss before training is 0.0040935412486691886 -- epoch number 941\n",
      "\n",
      "\n",
      "loss before training is 0.004089105826572389 -- epoch number 942\n",
      "\n",
      "\n",
      "loss before training is 0.0040846799714318 -- epoch number 943\n",
      "\n",
      "\n",
      "loss before training is 0.004080263652394184 -- epoch number 944\n",
      "\n",
      "\n",
      "loss before training is 0.0040758568387387634 -- epoch number 945\n",
      "\n",
      "\n",
      "loss before training is 0.004071459499875896 -- epoch number 946\n",
      "\n",
      "\n",
      "loss before training is 0.004067071605347613 -- epoch number 947\n",
      "\n",
      "\n",
      "loss before training is 0.004062693124825724 -- epoch number 948\n",
      "\n",
      "\n",
      "loss before training is 0.004058324028111587 -- epoch number 949\n",
      "\n",
      "\n",
      "loss before training is 0.004053964285135547 -- epoch number 950\n",
      "\n",
      "\n",
      "loss before training is 0.004049613865955814 -- epoch number 951\n",
      "\n",
      "\n",
      "loss before training is 0.004045272740758344 -- epoch number 952\n",
      "\n",
      "\n",
      "loss before training is 0.0040409408798558364 -- epoch number 953\n",
      "\n",
      "\n",
      "loss before training is 0.004036618253687165 -- epoch number 954\n",
      "\n",
      "\n",
      "loss before training is 0.00403230483281637 -- epoch number 955\n",
      "\n",
      "\n",
      "loss before training is 0.004028000587932434 -- epoch number 956\n",
      "\n",
      "\n",
      "loss before training is 0.00402370548984894 -- epoch number 957\n",
      "\n",
      "\n",
      "loss before training is 0.004019419509501944 -- epoch number 958\n",
      "\n",
      "\n",
      "loss before training is 0.004015142617951314 -- epoch number 959\n",
      "\n",
      "\n",
      "loss before training is 0.00401087478637849 -- epoch number 960\n",
      "\n",
      "\n",
      "loss before training is 0.004006615986086596 -- epoch number 961\n",
      "\n",
      "\n",
      "loss before training is 0.004002366188499982 -- epoch number 962\n",
      "\n",
      "\n",
      "loss before training is 0.003998125365162552 -- epoch number 963\n",
      "\n",
      "\n",
      "loss before training is 0.003993893487738313 -- epoch number 964\n",
      "\n",
      "\n",
      "loss before training is 0.003989670528010372 -- epoch number 965\n",
      "\n",
      "\n",
      "loss before training is 0.003985456457879808 -- epoch number 966\n",
      "\n",
      "\n",
      "loss before training is 0.003981251249365898 -- epoch number 967\n",
      "\n",
      "\n",
      "loss before training is 0.003977054874604657 -- epoch number 968\n",
      "\n",
      "\n",
      "loss before training is 0.003972867305848727 -- epoch number 969\n",
      "\n",
      "\n",
      "loss before training is 0.003968688515467144 -- epoch number 970\n",
      "\n",
      "\n",
      "loss before training is 0.00396451847594333 -- epoch number 971\n",
      "\n",
      "\n",
      "loss before training is 0.003960357159876315 -- epoch number 972\n",
      "\n",
      "\n",
      "loss before training is 0.003956204539978721 -- epoch number 973\n",
      "\n",
      "\n",
      "loss before training is 0.003952060589076986 -- epoch number 974\n",
      "\n",
      "\n",
      "loss before training is 0.003947925280110131 -- epoch number 975\n",
      "\n",
      "\n",
      "loss before training is 0.003943798586130089 -- epoch number 976\n",
      "\n",
      "\n",
      "loss before training is 0.003939680480299915 -- epoch number 977\n",
      "\n",
      "\n",
      "loss before training is 0.003935570935894347 -- epoch number 978\n",
      "\n",
      "\n",
      "loss before training is 0.00393146992629834 -- epoch number 979\n",
      "\n",
      "\n",
      "loss before training is 0.003927377425007518 -- epoch number 980\n",
      "\n",
      "\n",
      "loss before training is 0.00392329340562627 -- epoch number 981\n",
      "\n",
      "\n",
      "loss before training is 0.003919217841868302 -- epoch number 982\n",
      "\n",
      "\n",
      "loss before training is 0.00391515070755541 -- epoch number 983\n",
      "\n",
      "\n",
      "loss before training is 0.003911091976617472 -- epoch number 984\n",
      "\n",
      "\n",
      "loss before training is 0.003907041623091665 -- epoch number 985\n",
      "\n",
      "\n",
      "loss before training is 0.003902999621121348 -- epoch number 986\n",
      "\n",
      "\n",
      "loss before training is 0.0038989659449567217 -- epoch number 987\n",
      "\n",
      "\n",
      "loss before training is 0.0038949405689528223 -- epoch number 988\n",
      "\n",
      "\n",
      "loss before training is 0.003890923467570408 -- epoch number 989\n",
      "\n",
      "\n",
      "loss before training is 0.003886914615374615 -- epoch number 990\n",
      "\n",
      "\n",
      "loss before training is 0.0038829139870341766 -- epoch number 991\n",
      "\n",
      "\n",
      "loss before training is 0.0038789215573215275 -- epoch number 992\n",
      "\n",
      "\n",
      "loss before training is 0.0038749373011124667 -- epoch number 993\n",
      "\n",
      "\n",
      "loss before training is 0.0038709611933844816 -- epoch number 994\n",
      "\n",
      "\n",
      "loss before training is 0.0038669932092174134 -- epoch number 995\n",
      "\n",
      "\n",
      "loss before training is 0.0038630333237921126 -- epoch number 996\n",
      "\n",
      "\n",
      "loss before training is 0.003859081512390774 -- epoch number 997\n",
      "\n",
      "\n",
      "loss before training is 0.0038551377503954786 -- epoch number 998\n",
      "\n",
      "\n",
      "loss before training is 0.0038512020132885293 -- epoch number 999\n",
      "\n",
      "\n",
      "loss before training is 0.003847274276651328 -- epoch number 1000\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "\n",
    "#------------------------------------------Forward Propagation-------------------------------------------------\n",
    "    \n",
    "    in_hidden_1 = w1.dot(x) + b1\n",
    "    out_hidden_1 = sig(in_hidden_1)\n",
    "\n",
    "    in_hidden_2 = w2.dot(out_hidden_1) + b2\n",
    "    out_hidden_2 = softmax(in_hidden_2)\n",
    "\n",
    "    in_output_layer = w3.dot(out_hidden_2) + b3\n",
    "    y_hat = softmax(in_output_layer)\n",
    "    \n",
    "    loss = cross_E(y, y_hat)\n",
    "    print(f'loss before training is {loss} -- epoch number {epoch + 1}')\n",
    "    print('\\n')\n",
    "    \n",
    "#-----------------------------------------Gradient Calculations via Back Propagation---------------------------\n",
    "\n",
    "    error_upto_softmax = np.sum(cross_E_grad(y, y_hat) * softmax_dash(in_output_layer), axis = 0).reshape((-1, 1))\n",
    "    \n",
    "    grad_w3 = error_upto_softmax .dot( out_hidden_2.T )\n",
    "    \n",
    "    grad_b3 = error_upto_softmax\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    \n",
    "    error_grad_upto_H2 = np.sum(error_upto_softmax * w3, axis = 0) .reshape((-1, 1))\n",
    "    \n",
    "    error_upto_softmax_H2 = np.sum(error_grad_upto_H2 * softmax_dash(in_hidden_2), axis = 0).reshape((-1, 1))\n",
    "    \n",
    "    grad_w2 = error_upto_softmax_H2 .dot( out_hidden_1.T )\n",
    "    \n",
    "    grad_b2 = error_upto_softmax_H2\n",
    "    \n",
    "    #-----------------------------------------\n",
    "    \n",
    "    error_grad_upto_H1 = np.sum(error_upto_softmax_H2 * w2, axis = 0) .reshape((-1, 1))\n",
    "    \n",
    "    grad_w1 = error_grad_upto_H1 * sig_dash(in_hidden_1) .dot( x.T )\n",
    "    \n",
    "    grad_b1 = error_grad_upto_H1 * sig_dash(in_hidden_1)\n",
    "    \n",
    "#-----------------------------------------Updating weights and biases via SGD Momentum------------------------\n",
    "\n",
    "    update_w1 = - learning_rate * grad_w1 + momentum * update_w1\n",
    "    w1 += update_w1\n",
    "    \n",
    "    update_b1 = - learning_rate * grad_b1 + momentum * update_b1\n",
    "    b1 += update_b1\n",
    "    \n",
    "    update_w2 = - learning_rate * grad_w2 + momentum * update_w2\n",
    "    w2 += update_w2\n",
    "    \n",
    "    update_b2 = - learning_rate * grad_b2 + momentum * update_b2\n",
    "    b2 += update_b2\n",
    "    \n",
    "    update_w3 = - learning_rate * grad_w3 + momentum * update_w3\n",
    "    w3 += update_w3\n",
    "    \n",
    "    update_b3 = - learning_rate * grad_b3 + momentum * update_b3\n",
    "    b3 += update_b3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elegant-philippines",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retired-belief",
   "metadata": {},
   "source": [
    "**Forward feed after training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "inner-province",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0011485 ],\n",
       "       [0.99616402],\n",
       "       [0.00134445],\n",
       "       [0.00134303]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_hidden_1 = w1.dot(x) + b1\n",
    "out_hidden_1 = sig(in_hidden_1)\n",
    "\n",
    "in_hidden_2 = w2.dot(out_hidden_1) + b2\n",
    "out_hidden_2 = softmax(in_hidden_2)\n",
    "\n",
    "in_output_layer = w3.dot(out_hidden_2) + b3\n",
    "y_hat = softmax(in_output_layer)\n",
    "\n",
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "burning-jefferson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dying-supervision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0038433545161639282"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_E(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f257f84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "5147a8decd31e7b15d80b003c7388619c1258d9dc84c7b27bb729bd71864e42d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
