{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"SRGAN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Скачиваем данные"],"metadata":{"id":"lEcjpmvvzO_b"}},{"cell_type":"code","metadata":{"id":"N5OZ5GBZaUYa"},"source":["!wget http://data.vision.ee.ethz.ch/cvl/DIV2K/DIV2K_train_HR.zip\n","!unzip DIV2K_train_HR.zip"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Устанавливаем метрики для валидации\n","!pip install torchmetrics"],"metadata":{"id":"jrMGRbREgLrP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Имортируеем зависимости"],"metadata":{"id":"gLGhB-W-cIhP"}},{"cell_type":"code","metadata":{"id":"tI0KcjC3auG4"},"source":["import os\n","\n","from os.path import join\n","from os import listdir\n","\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import nn, optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader, Dataset\n","\n","\n","import math\n","\n","import numpy as np\n","\n","import torchvision\n","from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize\n","from torchvision.models.vgg import vgg16\n","from torchmetrics import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n","\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgr0F6vldlcC","outputId":"0b5c9f4d-3f43-440d-bf9b-f228b0380bf9"},"source":["torch.autograd.set_detect_anomaly(True)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fe4b9106b50>"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"Y9gCiSoBdnXC"},"source":["UPSCALE_FACTOR = 4\n","CROP_SIZE = 88"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Создаем даталоадер и загрузчик данных"],"metadata":{"id":"VIfTD7GScUbj"}},{"cell_type":"code","metadata":{"id":"N0tpRB2Jdys4"},"source":["def is_image_file(filename):\n","    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n","\n","\n","def calculate_valid_crop_size(crop_size, upscale_factor):\n","    return crop_size - (crop_size % upscale_factor)\n","\n","\n","def train_hr_transform(crop_size):\n","    return Compose([\n","        RandomCrop(crop_size),\n","        ToTensor(),\n","    ])\n","\n","\n","def train_lr_transform(crop_size, upscale_factor):\n","    return Compose([\n","        ToPILImage(),\n","        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n","        ToTensor()\n","    ])\n","\n","\n","class TrainDatasetFromFolder(Dataset):\n","    def __init__(self, dataset_dir, crop_size, upscale_factor):\n","        super(TrainDatasetFromFolder, self).__init__()\n","        self.image_filenames = [join(dataset_dir, x) for x in listdir(dataset_dir) if is_image_file(x)]\n","        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n","        self.hr_transform = train_hr_transform(crop_size)\n","        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n","\n","    def __getitem__(self, index):\n","        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n","        lr_image = self.lr_transform(hr_image)\n","        return lr_image, hr_image\n","\n","    def __len__(self):\n","        return len(self.image_filenames)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"re2-OAGQv-aQ","colab":{"base_uri":"https://localhost:8080/"},"outputId":"273ffcaa-7d83-4198-9b4c-243d04fd28ef"},"source":["train_set = TrainDatasetFromFolder(\"DIV2K_train_HR\", crop_size=CROP_SIZE,\n","                                   upscale_factor=UPSCALE_FACTOR)\n","trainloader = DataLoader(train_set, batch_size=64, num_workers=2, shuffle=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n"]}]},{"cell_type":"markdown","source":["# Архитектуры\n"],"metadata":{"id":"cn-CVP5HnNQ5"}},{"cell_type":"markdown","source":["## Ваше решение здесь!\n","\n","Вам требуется написать forward метод для residual блока\n"],"metadata":{"id":"gYNFuY9HzURE"}},{"cell_type":"code","metadata":{"id":"DQGAwDSGwUnE"},"source":["class ResidualBlock(nn.Module):\n","  def __init__(self, channels):\n","    super(ResidualBlock, self).__init__()\n","    self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","    self.bn1 = nn.BatchNorm2d(channels)\n","    self.prelu = nn.PReLU()\n","    self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n","    self.bn2 = nn.BatchNorm2d(channels)\n","  def forward(self, x):\n","    # Нужно написать forward, x+f(x)\n","    pass #... input your solution here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GNpcnPmbw6QQ"},"source":["class UpsampleBlock(nn.Module):\n","  def __init__(self, in_channels, up_scale):\n","    super(UpsampleBlock, self).__init__()\n","    self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, \n","                          kernel_size=3, padding=1)\n","    self.pixel_shuffle = nn.PixelShuffle(up_scale)\n","    self.prelu = nn.PReLU()\n","  def forward(self, x):\n","    x = self.conv(x)\n","    x = self.pixel_shuffle(x)\n","    x = self.prelu(x)\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## И ваше решение здесь\n","Нужно имплементировать слои как в статье\n","\n","https://arxiv.org/abs/1609.04802"],"metadata":{"id":"cnQ7AwQLzXLZ"}},{"cell_type":"code","metadata":{"id":"ZZnfl5c0uzUI"},"source":["class Generator(nn.Module):\n","  def __init__(self, scale_factor):\n","    super(Generator, self).__init__()\n","    upsample_block_num = int(math.log(scale_factor, 2))\n","\n","    self.block1 = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=9, padding=4),\n","        nn.PReLU()\n","    )\n","\n","    # Нужно доимплементировать слои\n","    self.block2 = #... input your solution\n","    self.block3 = #... input your solution\n","    self.block4 = #... input your solution\n","    self.block5 = #... input your solution\n","    self.block6 = #... input your solution\n","    self.block7 = nn.Sequential(\n","        nn.Conv2d(64, 64, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(64)\n","    )\n","    block8 = [UpsampleBlock(64, 2) for _ in range(upsample_block_num)]\n","    block8.append(nn.Conv2d(64, 3, kernel_size=9, padding=4))\n","    self.block8 = nn.Sequential(*block8)\n","  def forward(self, x):\n","    block1 = self.block1(x)\n","    block2 = self.block2(block1)\n","    block3 = self.block3(block2)\n","    block4 = self.block4(block3)\n","    block5 = self.block5(block4)\n","    block6 = self.block6(block5)\n","    block7 = self.block7(block6)\n","    block8 = self.block8(block1 + block7)\n","    return (torch.tanh(block8) + 1) / 2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ue5xbeyUuzWF"},"source":["class Discriminator(nn.Module):\n","  def __init__(self):\n","    super(Discriminator, self).__init__()\n","    self.net = nn.Sequential(\n","        nn.Conv2d(3, 64, kernel_size=3, padding=1),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(64),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(64, 128, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(128),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(128, 256, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(256, 256, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(256),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(256, 512, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.Conv2d(512, 512, kernel_size=3, stride=2, padding=1),\n","        nn.BatchNorm2d(512),\n","        nn.LeakyReLU(0.2),\n","\n","        nn.AdaptiveAvgPool2d(1),\n","        nn.Conv2d(512, 1024, kernel_size=1),\n","        nn.LeakyReLU(0.2),\n","        nn.Conv2d(1024, 1, kernel_size=1)\n","    )\n","  def forward(self, x):\n","    batch_size=x.size()[0]\n","    return torch.sigmoid(self.net(x).view(batch_size))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Лосс функции"],"metadata":{"id":"Fm-JqF3ZmL7T"}},{"cell_type":"code","metadata":{"id":"RamJwy7yxitq"},"source":["class TVLoss(nn.Module):\n","  def __init__(self, tv_loss_weight=1):\n","    super(TVLoss, self).__init__()\n","    self.tv_loss_weight=tv_loss_weight\n","    \n","  def forward(self, x):\n","    batch_size=x.size()[0]\n","    h_x = x.size()[2]\n","    w_x = x.size()[3]\n","\n","    count_h = self.tensor_size(x[:, :, 1:, :])\n","    count_w = self.tensor_size(x[:, :, :, 1:])\n","\n","    h_tv = torch.pow(x[:, :, 1:, :] - x[:, :, :h_x - 1, :], 2).sum()\n","    w_tv = torch.pow(x[:, :, :, 1:] - x[:, :, :, :w_x - 1], 2).sum()\n","    return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n","  \n","  @staticmethod\n","  def tensor_size(t):\n","    return t.size()[1] * t.size()[2] * t.size()[3]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OiwFaF3tySU_"},"source":["class GeneratorLoss(nn.Module):\n","  def __init__(self):\n","    super(GeneratorLoss, self).__init__()\n","    vgg = vgg16(pretrained=True)\n","    loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n","    for param in loss_network.parameters():\n","      param.requires_grad = False\n","    self.loss_network = loss_network\n","    self.mse_loss = nn.MSELoss()\n","    self.tv_loss = TVLoss()\n","    \n","  def forward(self, out_labels, out_images, target_images):\n","    adversial_loss = torch.mean(1 - out_labels)\n","    perception_loss = self.mse_loss(out_images, target_images)\n","    image_loss = self.mse_loss(out_images, target_images)\n","    tv_loss = self.tv_loss(out_images)\n","    return image_loss + 0.001 * adversial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tzzSCJjjy7I9","colab":{"base_uri":"https://localhost:8080/"},"outputId":"44881d22-f443-4268-f03e-62a7e679d222"},"source":["device  = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# Standard device selectoin\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"4oGBnX7PLGJ-"},"source":["netG = Generator(UPSCALE_FACTOR)\n","netD = Discriminator()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n39cIDQeLJFO"},"source":["generator_criterion = GeneratorLoss()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7ynXcO-8LSgN"},"source":["generator_criterion = generator_criterion.to(device)\n","netG = netG.to(device)\n","netD = netD.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gDlYj1loLiD_"},"source":["optimizerG = optim.Adam(netG.parameters(), lr=0.0002)\n","optimizerD = optim.Adam(netD.parameters(), lr=0.0002)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"doBMeLWOLs_0"},"source":["results = {\n","    \"d_loss\":[],\n","    \"g_loss\":[],\n","    \"d_score\": [],\n","    \"g_score\": []\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BeTxlp0eML1d"},"source":["N_EPOCHS = 150"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Обучение"],"metadata":{"id":"JqdEiCbemQNz"}},{"cell_type":"code","metadata":{"id":"iHadZtxcMO01"},"source":["for epoch in range(1, N_EPOCHS + 1):\n","  train_bar = tqdm(trainloader)\n","  running_results = {'batch_sizes':0, 'd_loss':0,\n","                     \"g_loss\":0, \"d_score\":0, \"g_score\":0}\n","\n","  metrics = [PeakSignalNoiseRatio(), StructuralSimilarityIndexMeasure()]\n","\n","  netG.train()\n","  netD.train()\n","  for data, target in train_bar:\n","    g_update_first = True\n","    batch_size = data.size(0)\n","    running_results['batch_sizes'] += batch_size\n","\n","    real_img = Variable(target)\n","    real_img = real_img.to(device)\n","    z = Variable(data)\n","    z = z.to(device)\n","\n","    ## Update Discriminator \n","    fake_img = netG(z)\n","    netD.zero_grad()\n","    real_out = netD(real_img).mean()\n","    fake_out = netD(fake_img).mean()\n","    d_loss = 1 - real_out + fake_out\n","    d_loss.backward(retain_graph = True)\n","    optimizerD.step()\n","    \n","    ## Now update Generator\n","    fake_img = netG(z)\n","    fake_out = netD(fake_img).mean()\n","    netG.zero_grad()\n","    g_loss = generator_criterion(fake_out, fake_img, real_img)\n","    g_loss.backward()\n","\n","    fake_img = netG(z)\n","    fake_out = netD(fake_img).mean()\n","\n","    optimizerG.step()\n","\n","    running_results['g_loss'] += g_loss.item() * batch_size\n","    running_results['d_loss'] += d_loss.item() * batch_size\n","    running_results['d_score'] += real_out.item() * batch_size\n","    running_results['g_score'] += real_out.item() * batch_size\n","    metrics[0](real_img.detach().cpu()*255, fake_img.detach().cpu()*255).item()\n","    metrics[1](real_img.detach().cpu()*255, fake_img.detach().cpu()*255).item()\n","\n","    ## Updating the progress bar\n","    train_bar.set_description(desc=\"[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f PSNR: %2f SSIM: %2f\" % (\n","        epoch, N_EPOCHS, running_results['d_loss'] / running_results['batch_sizes'],\n","        running_results['g_loss'] / running_results['batch_sizes'],\n","        running_results['d_score'] / running_results['batch_sizes'],\n","        running_results['g_score'] / running_results['batch_sizes'],\n","        metrics[0].compute().item(),\n","        metrics[1].compute().item()\n","\n","    ))\n","  netG.eval()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Визуализация"],"metadata":{"id":"ojdfKJ9AnG4Q"}},{"cell_type":"code","source":["def plot_images(images):\n","  grid_img = torchvision.utils.make_grid(images.detach().cpu()[:16])\n","  grid_img = (grid_img.permute(1, 2, 0).numpy()*255)\n","\n","  plt.figure(figsize=(20, 20))\n","  plt.imshow(grid_img.astype(np.uint8))"],"metadata":{"id":"f_tWatOGrfoP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plot_images(fake_img)\n","plot_images(real_img)"],"metadata":{"id":"VKlN5jD1Pm6k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"KS4UtJr2sM0x"},"execution_count":null,"outputs":[]}]}