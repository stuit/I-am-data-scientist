{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MedSRGAN.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["## Скачка данных и импорт пакетов"],"metadata":{"id":"RzTuFO75uwyO"}},{"cell_type":"code","source":["!mkdir ~/.kaggle\n","!pip install kaggle\n","!cp kaggle.json ~/.kaggle/kaggle.json\n","!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZ22Poae6fB3","outputId":"1a1d0eb5-4977-4bfe-d32b-d267c1127a54"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.10.8)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.0.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.3)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n","Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /root/.kaggle/kaggle.json'\n","Downloading chest-xray-pneumonia.zip to /content\n","100% 2.29G/2.29G [00:36<00:00, 84.2MB/s]\n","100% 2.29G/2.29G [00:36<00:00, 67.7MB/s]\n"]}]},{"cell_type":"code","source":["!unzip -qq chest-xray-pneumonia.zip"],"metadata":{"id":"BgFmXrNc6qDY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b3f0Sg0q6sPA","outputId":"01522441-c5d0-4e31-e62f-0ee1fad436f4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting torchmetrics\n","  Downloading torchmetrics-0.7.2-py3-none-any.whl (397 kB)\n","\u001b[?25l\r\u001b[K     |▉                               | 10 kB 21.8 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 20 kB 21.3 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 40 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 51 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 61 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 71 kB 13.0 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 81 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 92 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 102 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 112 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 122 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 133 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 143 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 153 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 163 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 174 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 184 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 194 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 204 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 215 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 225 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 235 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 245 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 256 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 266 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 276 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 286 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 296 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 307 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 317 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 327 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 337 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 348 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 358 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 368 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 378 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 389 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 397 kB 15.9 MB/s \n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n","Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.10.0+cu111)\n","Collecting pyDeprecate==0.3.*\n","  Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.1->torchmetrics) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.7)\n","Installing collected packages: pyDeprecate, torchmetrics\n","Successfully installed pyDeprecate-0.3.2 torchmetrics-0.7.2\n"]}]},{"cell_type":"code","source":["import os\n","\n","from tqdm import tqdm\n","\n","import torch\n","import torch.nn.functional as F\n","from torch import nn, optim\n","from torch.autograd import Variable\n","from torch.utils.data import DataLoader, Dataset\n","\n","\n","import math\n","\n","import numpy as np\n","\n","import torchvision\n","from torchvision.transforms import Compose, RandomCrop, ToTensor, ToPILImage, CenterCrop, Resize, Grayscale\n","from torchmetrics import StructuralSimilarityIndexMeasure, PeakSignalNoiseRatio\n","\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline"],"metadata":{"id":"ORzIpsvn6u0o"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Загрузка данных\n"],"metadata":{"id":"BXCxMSg7u5VW"}},{"cell_type":"code","source":["UPSCALE_FACTOR = 4\n","CROP_SIZE = 512"],"metadata":{"id":"jmZnZmkA7OeD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def is_image_file(filename):\n","    return any(filename.endswith(extension) for extension in ['.png', '.jpg', '.jpeg', '.PNG', '.JPG', '.JPEG'])\n","\n","\n","def calculate_valid_crop_size(crop_size, upscale_factor):\n","    return crop_size - (crop_size % upscale_factor)\n","\n","\n","def train_hr_transform(crop_size):\n","    return Compose([\n","        Resize(1024),\n","        Grayscale(),\n","        RandomCrop(crop_size),\n","        ToTensor(),\n","    ])\n","\n","\n","def train_lr_transform(crop_size, upscale_factor):\n","    return Compose([\n","        ToPILImage(),\n","        Grayscale(),\n","        Resize(crop_size // upscale_factor, interpolation=Image.BICUBIC),\n","        ToTensor()\n","    ])\n","\n","\n","class TrainDatasetFromFolder(Dataset):\n","    def __init__(self, dataset_dir, crop_size, upscale_factor):\n","        super(TrainDatasetFromFolder, self).__init__()\n","        self.image_filenames =  [os.path.join(r,file) for r,d,f in os.walk(dataset_dir) for file in f if is_image_file(file)]\n","        crop_size = calculate_valid_crop_size(crop_size, upscale_factor)\n","        self.hr_transform = train_hr_transform(crop_size)\n","        self.lr_transform = train_lr_transform(crop_size, upscale_factor)\n","\n","    def __getitem__(self, index):\n","        hr_image = self.hr_transform(Image.open(self.image_filenames[index]))\n","        lr_image = self.lr_transform(hr_image)\n","        return lr_image, hr_image\n","\n","    def __len__(self):\n","        return len(self.image_filenames)"],"metadata":{"id":"jFqR6S0h6zzR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set = TrainDatasetFromFolder(\"chest_xray/train\", crop_size=CROP_SIZE,\n","                                   upscale_factor=UPSCALE_FACTOR)\n","trainloader = DataLoader(train_set, batch_size=2, num_workers=4, shuffle=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjOfSopP63iJ","outputId":"604fe264-ca09-47e7-a9b1-6202632f64de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torchvision/transforms/transforms.py:288: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n","  \"Argument interpolation should be of type InterpolationMode instead of int. \"\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}]},{"cell_type":"markdown","source":["## Модель"],"metadata":{"id":"mLTFUQGDu8Pd"}},{"cell_type":"code","source":["class RWMAB(nn.Module):\n","  def __init__(self, in_channels):\n","    self.part1 = nn.Sequential(\n","        nn.Conv2d(in_channels, in_channels, (3, 3), stride=1, padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels, in_channels, (3, 3), stride=1, padding=1)\n","    )\n","    self.part2 = nn.Sequential(\n","        nn.Conv2d(in_channels, in_channels, (1, 1), stride=1, padding=0),\n","        nn.Sigmoid()\n","    )\n","\n","  def forward(self, x):\n","    x1 = self.part1(x)\n","    x2 = self.part2(x)\n","\n","    return x2*x1+x\n","\n","\n","class ShortResidualBlock(nn.Module):\n","  def __init__(self, in_channels):\n","    super().__init__()\n","\n","    self.layers = nn.ModuleList([RWMAB(in_channels) for _ in range(16)])\n","\n","  def forward(self, x):\n","    x1 = x.clone()\n","\n","    for layer in self.layers:\n","      x1 = layer(x1)\n","    \n","    return x + x1\n","    \n","\n","class Generator(nn.Module):\n","    def __init__(self, in_channels=1, blocks=8):\n","      super().__init__()\n","      self.conv = nn.Conv2d(in_channels, 64, (3, 3), stride=1, padding=1)\n","\n","      self.short_blocks = nn.ModuleList(\n","          [ShortResidualBlock(64) for _ in range(blocks)]\n","      )\n","\n","      self.conv2 = nn.Conv2d(64, 64, (1, 1), stride=1, padding=0)\n","\n","      self.conv3 = nn.Sequential(\n","          nn.Conv2d(128, 256, (3, 3), stride=1, padding=1),\n","          nn.PixelShuffle(2),\n","          nn.Conv2d(64, 256, (3, 3), stride=1, padding=1),\n","          nn.PixelShuffle(2), \n","          nn.Conv2d(64, 1, (1, 1), stride=1, padding=0),\n","          nn.Sigmoid(),\n","      )\n","\n","    def forward(self, x):\n","      x = self.conv(x)\n","      x1 = x.clone()\n","\n","      for layer in self.short_blocks:\n","          x1 = layer(x1)\n","      x = torch.cat([self.conv2(x1), x], dim=1)\n","      x = self.conv3(x)\n","      return x"],"metadata":{"id":"n9lRRlxv961S"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class D_Block(nn.Module):\n","    def __init__(self, in_channels, out_channels, stride=2):\n","        super().__init__()\n","\n","        self.layer = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, (3, 3), stride=stride, padding=1),\n","            nn.BatchNorm2d(out_channels),\n","            nn.LeakyReLU(),\n","        )\n","\n","    def forward(self, x):\n","\n","        return self.layer(x)\n","\n","\n","class Discriminator(nn.Module):\n","    def __init__(self, img_size, in_channels=1):\n","        super().__init__()\n","\n","        self.conv_1_1 = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, (3, 3), stride=1, padding=1), nn.LeakyReLU()\n","        )\n","\n","        self.block_1_1 = D_Block(64, 64, stride=2)\n","        self.block_1_2 = D_Block(64, 128, stride=1)\n","        self.block_1_3 = D_Block(128, 128)\n","\n","        self.conv_2_1 = nn.Sequential(\n","            nn.Conv2d(in_channels, 64, (3, 3), stride=1, padding=1), nn.LeakyReLU()\n","        )\n","\n","        self.block_2_2 = D_Block(64, 128, stride=1)\n","\n","        self.block3 = D_Block(256, 256, stride=1)\n","        self.block4 = D_Block(256, 256)\n","        self.block5 = D_Block(256, 512, stride=1)\n","        self.block6 = D_Block(512, 512)\n","        self.block7 = D_Block(512, 1024)\n","        self.block8 = D_Block(1024, 1024)\n","\n","        self.flatten = nn.Flatten()\n","\n","        self.fc1 = nn.Linear(1024 * img_size[0] * img_size[1] // 256, 100)\n","        self.fc2 = nn.Linear(100, 2)\n","\n","        self.relu = nn.LeakyReLU(negative_slope=0.2)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x1, x2):\n","\n","        x_1 = self.block_1_3(self.block_1_2(self.block_1_1(self.conv_1_1(x1))))\n","        x_2 = self.block_2_2(self.conv_2_1(x2))\n","\n","        x = torch.cat([x_1, x_2], dim=1)\n","        x = self.block8(\n","            self.block7(self.block6(self.block5(self.block4(self.block3(x)))))\n","        )\n","\n","        x = self.flatten(x)\n","\n","\n","        x = self.fc1(x)\n","        x = self.fc2(self.relu(x))\n","\n","        return self.sigmoid(x)"],"metadata":{"id":"iZr-_-VJOUOB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Обучение, ваше решение\n","\n","Вам требуется имплементировать лосс функции, обучение, задать все оптимизаторы и прочие параметры как в srgan, а также, посчитать метрики. "],"metadata":{"id":"EHAvniszvAKW"}},{"cell_type":"code","source":[""],"metadata":{"id":"tWv94iEPvTey"},"execution_count":null,"outputs":[]}]}