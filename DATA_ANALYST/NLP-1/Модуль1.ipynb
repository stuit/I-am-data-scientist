{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mEb91VHf9Uao"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (4.30.2)\n",
            "Requirement already satisfied: sacremoses in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (0.0.53)\n",
            "Requirement already satisfied: filelock in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (1.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: six in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from sacremoses) (1.16.0)\n",
            "Requirement already satisfied: click in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from sacremoses) (8.1.5)\n",
            "Requirement already satisfied: joblib in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from sacremoses) (1.3.1)\n",
            "Requirement already satisfied: fsspec in c:\\users\\ilkhom-pc\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: colorama in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from requests->transformers) (2.0.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\programmfiles\\miniconda\\envs\\dev\\lib\\site-packages (from requests->transformers) (2023.5.7)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ilkhom-pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ilkhom-pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ilkhom-pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ilkhom-pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ilkhom-pc\\appdata\\roaming\\python\\python39\\site-packages)\n",
            "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\ilkhom-pc\\appdata\\roaming\\python\\python39\\site-packages)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers sacremoses\n",
        "from transformers import pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utg6bWTVbhbm"
      },
      "source": [
        "Тематическая классификация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rDdRQYeVZeth"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cls_pl \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39mtext-classification\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mnateraw/bert-base-uncased-ag-news\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      2\u001b[0m cls_pl(\u001b[39m'\u001b[39m\u001b[39mNLP is a field of linguistics and machine learning focused on understanding everything related to human language.\u001b[39m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32md:\\ProgrammFiles\\miniconda\\envs\\dev\\lib\\site-packages\\transformers\\pipelines\\__init__.py:788\u001b[0m, in \u001b[0;36mpipeline\u001b[1;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, use_auth_token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39m# Infer the framework from the model\u001b[39;00m\n\u001b[0;32m    785\u001b[0m \u001b[39m# Forced if framework already defined, inferred if it's None\u001b[39;00m\n\u001b[0;32m    786\u001b[0m \u001b[39m# Will load the correct model if possible\u001b[39;00m\n\u001b[0;32m    787\u001b[0m model_classes \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mtf\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m: targeted_task[\u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m]}\n\u001b[1;32m--> 788\u001b[0m framework, model \u001b[39m=\u001b[39m infer_framework_load_model(\n\u001b[0;32m    789\u001b[0m     model,\n\u001b[0;32m    790\u001b[0m     model_classes\u001b[39m=\u001b[39mmodel_classes,\n\u001b[0;32m    791\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m    792\u001b[0m     framework\u001b[39m=\u001b[39mframework,\n\u001b[0;32m    793\u001b[0m     task\u001b[39m=\u001b[39mtask,\n\u001b[0;32m    794\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mhub_kwargs,\n\u001b[0;32m    795\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mmodel_kwargs,\n\u001b[0;32m    796\u001b[0m )\n\u001b[0;32m    798\u001b[0m model_config \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\n\u001b[0;32m    799\u001b[0m hub_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39m_commit_hash\n",
            "File \u001b[1;32md:\\ProgrammFiles\\miniconda\\envs\\dev\\lib\\site-packages\\transformers\\pipelines\\base.py:221\u001b[0m, in \u001b[0;36minfer_framework_load_model\u001b[1;34m(model, config, model_classes, task, framework, **model_kwargs)\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[39mSelect framework (TensorFlow or PyTorch) to use from the `model` passed. Returns a tuple (framework, model).\u001b[39;00m\n\u001b[0;32m    197\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39m    `Tuple`: A tuple framework, model.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tf_available() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_available():\n\u001b[1;32m--> 221\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    222\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAt least one of TensorFlow 2.0 or PyTorch should be installed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    223\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    224\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mTo install PyTorch, read the instructions at https://pytorch.org/.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    225\u001b[0m     )\n\u001b[0;32m    226\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(model, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    227\u001b[0m     model_kwargs[\u001b[39m\"\u001b[39m\u001b[39m_from_pipeline\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m task\n",
            "\u001b[1;31mRuntimeError\u001b[0m: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/."
          ]
        }
      ],
      "source": [
        "cls_pl = pipeline(\"text-classification\", \"nateraw/bert-base-uncased-ag-news\")\n",
        "cls_pl('NLP is a field of linguistics and machine learning focused on understanding everything related to human language.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8YEFQV8gpoW"
      },
      "source": [
        "Token classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZ5iPN-GgvI2"
      },
      "outputs": [],
      "source": [
        "ner_pipeline = pipeline(\"ner\", \"dslim/bert-base-NER\", aggregation_strategy=\"first\")\n",
        "ner_pipeline(\"Matthew Carrigan is a Machine Learning Engineer at Hugging Face. He lives in Dublin, Ireland and previously worked as an ML engineer at Parse.ly and before that as a post-doctoral researcher at Trinity College Dublin.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUKynAykbT2z"
      },
      "source": [
        "Перевод с русского на английский"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNHfmGA2-LtD"
      },
      "outputs": [],
      "source": [
        "ru_en_translator = pipeline(\"translation_ru_to_en\", \"facebook/wmt19-ru-en\")\n",
        "ru_en_translator(\"Мэтью Кэрриган - инженер-механик в компании Hugging Face. Он живет в Дублине, Ирландия, а до этого работал инженером-программистом в Parse.ly, а до этого - постдоком-исследователем в дублинском колледже Trinity College.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dI-0CwXObcBr"
      },
      "source": [
        "Перевод с английского на русский"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FiLVAnY_nMBF"
      },
      "outputs": [],
      "source": [
        "txt = \"Matthew Carrigan is a Machine Learning Engineer at Hugging Face. He lives in Dublin, Ireland and previously worked as an ML engineer at Parse.ly and before that as a post-doctoral researcher at Trinity College Dublin.\"\n",
        "en_ru_translator = pipeline(\"translation_en_to_ru\", \"facebook/wmt19-en-ru\")\n",
        "en_ru_translator(txt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dly4UU3qblgP"
      },
      "source": [
        "Аннотирование"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8JP8zyK2jU8"
      },
      "outputs": [],
      "source": [
        "sum_pipeline = pipeline(\"summarization\", \"IlyaGusev/rut5_base_sum_gazeta\")\n",
        "sum_pipeline(\"Естественным развитием задач классификации всего текста или его фрагментов является классификация отдельных слов в предложении. Наиболее распространенной задачей такого вида является задача выделения именованных сущностей (NER - named entity recognition) - в данном случае необходимо для каждого слова в тексте проставить класс принадлежности его к тому или иному типу сущности (например, организация, персона, локация и т.д.), либо пустой класс, показывающий, что слово не относится ни к одному из рассматриваемых классов. С помощью NER можно разрабатывать системы автоматического заполнения форм документов, составления отчетов о компаниях, нахождения разных упоминания одних и тех же сущностей (это задача entity linking - она решается после ner), удаления персональной информации из текстов и т.д. Кроме классификации слов текста на именованные сущности, можно производить классификацию по каким-то другим критериям - например, по частям речи (хотя это практическое использование такого рода задач гораздо уже).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xlY3IfzeG1H"
      },
      "source": [
        "Поиск ответа на вопрос"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AE5MqwPmbQzu"
      },
      "outputs": [],
      "source": [
        "qa_pipeline = pipeline(\"question-answering\", \"deepset/roberta-base-squad2\")\n",
        "question = \"Which name is also used to describe the Amazon rainforest in English?\"\n",
        "context = \"The Amazon rainforest (Portuguese: Floresta Amazônica or Amazônia; Spanish: Selva Amazónica, Amazonía or usually Amazonia; French: Forêt amazonienne; Dutch: Amazoneregenwoud), also known in English as Amazonia or the Amazon Jungle, is a moist broadleaf forest that covers most of the Amazon basin of South America. This basin encompasses 7,000,000 square kilometres (2,700,000 sq mi), of which 5,500,000 square kilometres (2,100,000 sq mi) are covered by the rainforest. This region includes territory belonging to nine nations. The majority of the forest is contained within Brazil, with 60% of the rainforest, followed by Peru with 13%, Colombia with 10%, and with minor amounts in Venezuela, Ecuador, Bolivia, Guyana, Suriname and French Guiana. States or departments in four nations contain \\\"Amazonas\\\" in their names. The Amazon represents over half of the planet's remaining rainforests, and comprises the largest and most biodiverse tract of tropical rainforest in the world, with an estimated 390 billion individual trees divided into 16,000 species.\"\n",
        "qa_pipeline(question, context)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Модуль1(1).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
