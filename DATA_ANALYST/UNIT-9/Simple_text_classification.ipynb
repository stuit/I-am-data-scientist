{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1DNiHsB0bvg"
      },
      "source": [
        "# Классификация текста простыми методами"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZG4CmD10mnd"
      },
      "source": [
        "Загружем необходимые данные для nltk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpFTvZC_j0ac",
        "outputId": "3946e968-0647-4a50-ea34-be5c77c8a6ed"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/ilkhom/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /Users/ilkhom/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /Users/ilkhom/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/ilkhom/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ikyrc05w1EKV"
      },
      "source": [
        "Мы будем использовать датасет fetch_20newsgroups. Он содержит коллекции новостей с 20 различных источников. Но мы возьмем только 4."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ivAOt423fyiv"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "categories = ['sci.crypt', 'sci.electronics', 'sci.med', 'sci.space']\n",
        "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories)\n",
        "newsgroups_test = fetch_20newsgroups(subset='test', categories=categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6O1EiR72oCG",
        "outputId": "b2d40cdf-914e-4a6f-b340-342adf393a97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{0, 1, 2, 3}"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "set(newsgroups_train.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVH0XPGj4zc6"
      },
      "source": [
        "Загружаем данные и таргеты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "74KIxchqgr8A"
      },
      "outputs": [],
      "source": [
        "X_train = newsgroups_train.data\n",
        "y_train = newsgroups_train.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WgX3xrFkibXw"
      },
      "outputs": [],
      "source": [
        "X_test = newsgroups_test.data\n",
        "y_test = newsgroups_test.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGtQT3YO48J-"
      },
      "source": [
        "Смотрим на количество данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0qDNIBUhfXb",
        "outputId": "9fff80c6-e848-49d7-8916-4350cfa4cc0b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2373, 2373)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_train), len(y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkENH8hHtb81",
        "outputId": "0153affc-483e-4778-b3e5-4c422b48ca77"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1579, 1579)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(X_test), len(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iCpZKvs2SbA"
      },
      "source": [
        "TfidfVectorizer – это одновременно CountVectorizer после которого идет TfidfTransformer. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vld2k-ZAhigO",
        "outputId": "bc7edfcd-2eb8-482d-81cf-79fac4ced804"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2373, 38683)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train)\n",
        "X_train_vec.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9T_PY6L2U8q"
      },
      "source": [
        "Воспользуемся LogisticRegression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qhRu2fs-hysR",
        "outputId": "d979a261-7f7c-4573-efb4-9b6e41dd2410"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression()\n",
        "\n",
        "lr.fit(X_train_vec, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64hdTnSs2eyC"
      },
      "source": [
        "Оценим модель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vl-fyhWTiINv"
      },
      "outputs": [],
      "source": [
        "X_test_vec = X_train_vec = vectorizer.transform(X_test)\n",
        "y_pred = lr.predict(X_test_vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlWgYNM7iWQ5",
        "outputId": "6433abe6-e07a-4644-bf44-61aaa2479814"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      sci.crypt       0.95      0.90      0.93       396\n",
            "sci.electronics       0.80      0.94      0.86       393\n",
            "        sci.med       0.95      0.87      0.91       396\n",
            "      sci.space       0.97      0.93      0.95       394\n",
            "\n",
            "       accuracy                           0.91      1579\n",
            "      macro avg       0.92      0.91      0.91      1579\n",
            "   weighted avg       0.92      0.91      0.91      1579\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KooSMdhx2_Wa"
      },
      "source": [
        "## Предобработка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUbPbRP35NpP"
      },
      "source": [
        "До этого мы не применяли предобработку. Посмотрим насколько она нам может помочь."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lg5XYRZ5Sb0"
      },
      "source": [
        "Рассмотрим сначала предобработку на одном примере.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLvNKePU5xh3"
      },
      "source": [
        "Токенизируем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "From: al@escom.com (Al Donaldson)\n",
            "Subject: Re: Once tapped, your code is no good any more.\n",
            "Reply-To: al@escom.COM (Al Donaldson)\n",
            "Organization: ESCOM Corp., Oakton VA (USA)\n",
            "Distribution: na\n",
            "Lines: 16\n",
            "\n",
            "amolitor@nmsu.edu (Andrew Molitor) writes:\n",
            ">Yes, those evil guys in the FBI can probably, with some\n",
            ">effort, abuse the system. I got news for you, if the evil guys in\n",
            ">the FBI decide they want to persecute you, they're gonna, ...\n",
            "\n",
            "And if Richard Nixon had had this kind of toy, he wouldn't have had\n",
            "to send people into the Watergate.\n",
            "\n",
            "But that's not really the issue.  The real issue is whether this \n",
            "will be used to justify a ban against individuals' use of private \n",
            "(i.e., anything else) encryption methods.\n",
            "\n",
            "Unrelated question...isn't the term \"Clipper,\" as neat as it is,\n",
            "already taken by Intergraph?\n",
            "\n",
            "Al\n",
            "\n"
          ]
        }
      ],
      "source": [
        "x = X_train[0]\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "x = x.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "g1irV8YFkHJw",
        "outputId": "d28da794-ce05-4b29-d600-5cf4dd16e809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['from', ':', 'al', '@', 'escom.com', '(', 'al', 'donaldson', ')', 'subject', ':', 're', ':', 'once', 'tapped', ',', 'your', 'code', 'is', 'no', 'good', 'any', 'more', '.', 'reply-to', ':', 'al', '@', 'escom.com', '(', 'al', 'donaldson', ')', 'organization', ':', 'escom', 'corp.', ',', 'oakton', 'va', '(', 'usa', ')', 'distribution', ':', 'na', 'lines', ':', '16', 'amolitor', '@', 'nmsu.edu', '(', 'andrew', 'molitor', ')', 'writes', ':', '>', 'yes', ',', 'those', 'evil', 'guys', 'in', 'the', 'fbi', 'can', 'probably', ',', 'with', 'some', '>', 'effort', ',', 'abuse', 'the', 'system', '.', 'i', 'got', 'news', 'for', 'you', ',', 'if', 'the', 'evil', 'guys', 'in', '>', 'the', 'fbi', 'decide', 'they', 'want', 'to', 'persecute', 'you', ',', 'they', \"'re\", 'gon', 'na', ',', '...', 'and', 'if', 'richard', 'nixon', 'had', 'had', 'this', 'kind', 'of', 'toy', ',', 'he', 'would', \"n't\", 'have', 'had', 'to', 'send', 'people', 'into', 'the', 'watergate', '.', 'but', 'that', \"'s\", 'not', 'really', 'the', 'issue', '.', 'the', 'real', 'issue', 'is', 'whether', 'this', 'will', 'be', 'used', 'to', 'justify', 'a', 'ban', 'against', 'individuals', \"'\", 'use', 'of', 'private', '(', 'i.e.', ',', 'anything', 'else', ')', 'encryption', 'methods', '.', 'unrelated', 'question', '...', 'is', \"n't\", 'the', 'term', '``', 'clipper', ',', \"''\", 'as', 'neat', 'as', 'it', 'is', ',', 'already', 'taken', 'by', 'intergraph', '?', 'al']\n"
          ]
        }
      ],
      "source": [
        "x = nltk.word_tokenize(x)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTQMec6l57za"
      },
      "source": [
        "Удалим слова со знаками препинания."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4fp2MYNj0dD",
        "outputId": "a340c598-dd94-4590-dc83-d00254c391c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['from', 'al', 'al', 'donaldson', 'subject', 're', 'once', 'tapped', 'your', 'code', 'is', 'no', 'good', 'any', 'more', 'al', 'al', 'donaldson', 'organization', 'escom', 'oakton', 'va', 'usa', 'distribution', 'na', 'lines', '16', 'amolitor', 'andrew', 'molitor', 'writes', 'yes', 'those', 'evil', 'guys', 'in', 'the', 'fbi', 'can', 'probably', 'with', 'some', 'effort', 'abuse', 'the', 'system', 'i', 'got', 'news', 'for', 'you', 'if', 'the', 'evil', 'guys', 'in', 'the', 'fbi', 'decide', 'they', 'want', 'to', 'persecute', 'you', 'they', 'gon', 'na', 'and', 'if', 'richard', 'nixon', 'had', 'had', 'this', 'kind', 'of', 'toy', 'he', 'would', 'have', 'had', 'to', 'send', 'people', 'into', 'the', 'watergate', 'but', 'that', 'not', 'really', 'the', 'issue', 'the', 'real', 'issue', 'is', 'whether', 'this', 'will', 'be', 'used', 'to', 'justify', 'a', 'ban', 'against', 'individuals', 'use', 'of', 'private', 'anything', 'else', 'encryption', 'methods', 'unrelated', 'question', 'is', 'the', 'term', 'clipper', 'as', 'neat', 'as', 'it', 'is', 'already', 'taken', 'by', 'intergraph', 'al']\n"
          ]
        }
      ],
      "source": [
        "x = [word for word in x if word.isalnum()]\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkBoj68q6AU5"
      },
      "source": [
        "Лемматизируем."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /Users/ilkhom/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaBPzwyrj0fb",
        "outputId": "0d332e3b-85c9-41af-f8b6-489d383b9b4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['from', 'al', 'al', 'donaldson', 'subject', 're', 'once', 'tapped', 'your', 'code', 'be', 'no', 'good', 'any', 'more', 'al', 'al', 'donaldson', 'organization', 'escom', 'oakton', 'va', 'usa', 'distribution', 'na', 'line', '16', 'amolitor', 'andrew', 'molitor', 'writes', 'yes', 'those', 'evil', 'guy', 'in', 'the', 'fbi', 'can', 'probably', 'with', 'some', 'effort', 'abuse', 'the', 'system', 'i', 'get', 'news', 'for', 'you', 'if', 'the', 'evil', 'guy', 'in', 'the', 'fbi', 'decide', 'they', 'want', 'to', 'persecute', 'you', 'they', 'gon', 'na', 'and', 'if', 'richard', 'nixon', 'have', 'have', 'this', 'kind', 'of', 'toy', 'he', 'would', 'have', 'have', 'to', 'send', 'people', 'into', 'the', 'watergate', 'but', 'that', 'not', 'really', 'the', 'issue', 'the', 'real', 'issue', 'be', 'whether', 'this', 'will', 'be', 'use', 'to', 'justify', 'a', 'ban', 'against', 'individual', 'use', 'of', 'private', 'anything', 'else', 'encryption', 'method', 'unrelated', 'question', 'be', 'the', 'term', 'clipper', 'a', 'neat', 'a', 'it', 'be', 'already', 'take', 'by', 'intergraph', 'al']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "def get_wordnet_pos(word):\n",
        "     tag = nltk.pos_tag([word])[0][1][0].upper()\n",
        "     tag_dict = {\"J\": wordnet.ADJ, \"N\": wordnet.NOUN, \"V\": wordnet.VERB, \"R\": wordnet.ADV}\n",
        "     return tag_dict.get(tag, wordnet.NOUN)\n",
        "\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "x = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in x]\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wgylucV6J1p"
      },
      "source": [
        "Удалим стоп-слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s7Sjl6t6lJiI",
        "outputId": "f12e2c62-da99-4055-835e-71b76d227835"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "131\n",
            "['al', 'al', 'donaldson', 'subject', 'tapped', 'code', 'good', 'al', 'al', 'donaldson', 'organization', 'escom', 'oakton', 'va', 'usa', 'distribution', 'na', 'line', '16', 'amolitor', 'andrew', 'molitor', 'writes', 'yes', 'evil', 'guy', 'fbi', 'probably', 'effort', 'abuse', 'system', 'get', 'news', 'evil', 'guy', 'fbi', 'decide', 'want', 'persecute', 'gon', 'na', 'richard', 'nixon', 'kind', 'toy', 'would', 'send', 'people', 'watergate', 'really', 'issue', 'real', 'issue', 'whether', 'use', 'justify', 'ban', 'individual', 'use', 'private', 'anything', 'else', 'encryption', 'method', 'unrelated', 'question', 'term', 'clipper', 'neat', 'already', 'take', 'intergraph', 'al']\n",
            "73\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "print(len(x))\n",
        "x = [word for word in x if not word in stop_words]\n",
        "print(x)\n",
        "print(len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFflSZDLBpiZ",
        "outputId": "4cd949e8-d609-4284-db37-7841270963a8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2373/2373 [00:07<00:00, 312.79it/s]\n",
            "100%|██████████| 1579/1579 [00:04<00:00, 361.93it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def preprocces(X):\n",
        "  X_proccess = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "  for x in tqdm(X):\n",
        "    \n",
        "    x = x.lower()\n",
        "    x = nltk.word_tokenize(x)\n",
        "    x = [word for word in x if word.isalnum()]\n",
        "    x = [lemmatizer.lemmatize(w) for w in x]\n",
        "    x = [word for word in x if not word in stop_words]\n",
        "    X_proccess.append(' '.join(x))\n",
        "  return X_proccess\n",
        "\n",
        "\n",
        "X_train_proc = preprocces(X_train)\n",
        "X_test_proc = preprocces(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEJ_VN2xB1s-",
        "outputId": "2c7a889d-ca8b-41fb-960d-df4820984899"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2373, 29448)\n",
            "(1579, 29448)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
        "X_test_vec = vectorizer.transform(X_test_proc)\n",
        "print(X_train_vec.shape)\n",
        "print(X_test_vec.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hsMuhYAB3-B",
        "outputId": "e38e152b-1e2e-4705-f801-5bd7bcfb7b47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      sci.crypt       0.98      0.91      0.95       396\n",
            "sci.electronics       0.84      0.97      0.90       393\n",
            "        sci.med       0.96      0.92      0.94       396\n",
            "      sci.space       0.98      0.95      0.96       394\n",
            "\n",
            "       accuracy                           0.94      1579\n",
            "      macro avg       0.94      0.94      0.94      1579\n",
            "   weighted avg       0.94      0.94      0.94      1579\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_vec, y_train)\n",
        "y_pred = lr.predict(X_test_vec)\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xv4KdGEF3pi9"
      },
      "source": [
        "## Стемминг "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjAoIILi7S0b"
      },
      "source": [
        "Воспользуемся стеммингом вместо лемматизации"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLDlk5ZvsoFl",
        "outputId": "72e2d1fe-192a-46f3-8369-9752afb9f304"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2373/2373 [00:15<00:00, 152.74it/s]\n",
            "100%|██████████| 1579/1579 [00:09<00:00, 174.84it/s]\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "def preprocces(X):\n",
        "  X_proccess = []\n",
        "  stemmer = PorterStemmer()\n",
        "\n",
        "  for x in tqdm(X):\n",
        "    \n",
        "    x = x.lower()\n",
        "    x = nltk.word_tokenize(x)\n",
        "    x = [word for word in x if word.isalnum()]\n",
        "    x = [stemmer.stem(w) for w in x]\n",
        "    x = [word for word in x if not word in stop_words]\n",
        "    X_proccess.append(' '.join(x))\n",
        "  return X_proccess\n",
        "\n",
        "\n",
        "X_train_proc = preprocces(X_train)\n",
        "X_test_proc = preprocces(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0yyJKxgvpZZ",
        "outputId": "2cd0ae90-50e2-40e7-dec6-695e5596b604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2373, 24082)\n",
            "(1579, 24082)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_vec = vectorizer.fit_transform(X_train_proc)\n",
        "X_test_vec = vectorizer.transform(X_test_proc)\n",
        "print(X_train_vec.shape)\n",
        "print(X_test_vec.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8INNKEovp6x",
        "outputId": "02fa890a-6212-48a1-ceea-99b4085da8fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "      sci.crypt       0.96      0.92      0.94       396\n",
            "sci.electronics       0.84      0.95      0.89       393\n",
            "        sci.med       0.95      0.91      0.93       396\n",
            "      sci.space       0.99      0.94      0.96       394\n",
            "\n",
            "       accuracy                           0.93      1579\n",
            "      macro avg       0.93      0.93      0.93      1579\n",
            "   weighted avg       0.93      0.93      0.93      1579\n",
            "\n"
          ]
        }
      ],
      "source": [
        "lr = LogisticRegression()\n",
        "lr.fit(X_train_vec, y_train)\n",
        "y_pred = lr.predict(X_test_vec)\n",
        "\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred, target_names=newsgroups_train.target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oohUi82MB_c0"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
