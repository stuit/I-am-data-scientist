{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 337,
      "metadata": {
        "id": "hsP7cV1_arhs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torchtext import datasets\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import random\n",
        "\n",
        "from gensim.models import FastText\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 338,
      "metadata": {
        "id": "sNRfW260a3jg"
      },
      "outputs": [],
      "source": [
        "SEED = 1234\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 339,
      "metadata": {
        "id": "uyk3BCHza5ru"
      },
      "outputs": [],
      "source": [
        "train_data, _, test_data = datasets.UDPOS()\n",
        "train_data = [d for d in train_data]\n",
        "test_data = [d for d in test_data]\n",
        "\n",
        "train_tokens = [ [w.lower() for w in d[0]] for d in train_data]\n",
        "train_tags = [ d[1] for d in train_data]\n",
        "\n",
        "test_tokens = [[w.lower() for w in d[0]] for d in test_data]\n",
        "test_tags = [d[1] for d in test_data]\n",
        "\n",
        "tag2num = { t:i for i, t in enumerate(np.unique([tag for tags in train_tags for tag in tags])) }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 340,
      "metadata": {
        "id": "pBDDAUdhbxCq"
      },
      "outputs": [],
      "source": [
        "stemmer = PorterStemmer()\n",
        "\n",
        "word_to_ix = {}\n",
        "for tokens in train_tokens:\n",
        "    for word in tokens:\n",
        "        word = stemmer.stem(word)\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "\n",
        "word_to_ix[\"UNK\"] =  len(word_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 341,
      "metadata": {
        "id": "0hkWDYVab5PT"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/ww/67t1k6ss6bqfd8tw6ntmpfgm0000gn/T/ipykernel_16370/3345314622.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_vecs.append(torch.tensor(ids, dtype=torch.long))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([12543, 20]), torch.Size([12543, 20]))"
            ]
          },
          "execution_count": 341,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max_len = 20\n",
        "pad_inds = len(tag2num)\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    stemmer = PorterStemmer()\n",
        "    stemmed_words = [stemmer.stem(w) for w in seq]\n",
        "    idxs = [to_ix[w] if w in to_ix else to_ix[\"UNK\"] for w in stemmed_words ]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "\n",
        "def prepare_data_for_inner_embeddings(all_tokens, all_tags, word_to_ix, tag2num, max_len, pad_tags):\n",
        "    all_tags = [np.array([tag2num[tag]  for tag in tags]) for tags in all_tags]\n",
        "    \n",
        "    all_tokens = [tokens[:max_len] for tokens in all_tokens]\n",
        "    all_tags = [tags[:max_len] for tags in all_tags]\n",
        "    \n",
        "    all_ids = []\n",
        "    for tokens in all_tokens:\n",
        "        ids = prepare_sequence(tokens, word_to_ix)\n",
        "        all_ids.append(ids)\n",
        "        \n",
        "    X_vecs = []\n",
        "    Y_vecs = []\n",
        "\n",
        "    for ids, tags in zip(all_ids, all_tags):\n",
        "        X_vecs.append(torch.tensor(ids, dtype=torch.long))\n",
        "        Y_vecs.append(torch.tensor(tags, dtype=torch.long))\n",
        "        \n",
        "    # в качестве заполнителя X используем новый индекс len(word_to_ix)\n",
        "    X = pad_sequence(X_vecs, batch_first=True, padding_value=len(word_to_ix))\n",
        "\n",
        "    # в качестве заполнителя Y используем pad_tags\n",
        "    Y = pad_sequence(Y_vecs, batch_first=True, padding_value=pad_tags)\n",
        "    \n",
        "    return X, Y\n",
        "\n",
        "X_train, Y_train = prepare_data_for_inner_embeddings(train_tokens, train_tags, word_to_ix, tag2num, max_len, pad_inds)\n",
        "\n",
        "X_train.size(), Y_train.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 342,
      "metadata": {
        "id": "GYNHAQxZcHhS"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/ww/67t1k6ss6bqfd8tw6ntmpfgm0000gn/T/ipykernel_16370/3345314622.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_vecs.append(torch.tensor(ids, dtype=torch.long))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(torch.Size([2077, 20]), torch.Size([2077, 20]))"
            ]
          },
          "execution_count": 342,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test, Y_test = prepare_data_for_inner_embeddings(test_tokens, test_tags, word_to_ix, tag2num, max_len, pad_inds)\n",
        "\n",
        "X_test.size(), Y_test.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 343,
      "metadata": {
        "id": "UeBb8AbNcdX_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[    0,     1,     2,  ...,    14,    15,    11],\n",
            "        [   23,    24,     6,  ...,    37, 12121, 12121],\n",
            "        [   38,     3,    39,  ..., 12121, 12121, 12121],\n",
            "        ...,\n",
            "        [ 3083,    43,    28,  ...,   211,    29,    25],\n",
            "        [   11,  4206,    13,  ...,    17,   368,    42],\n",
            "        [  112,    28,   387,  ...,   132,    43,  1054]])\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 344,
      "metadata": {
        "id": "GfjixGEdceuN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[11, 12, 11,  ...,  7,  1,  5],\n",
            "        [12,  5,  7,  ..., 12, 17, 17],\n",
            "        [11, 12,  0,  ..., 17, 17, 17],\n",
            "        ...,\n",
            "        [ 2, 10,  3,  ...,  2,  3,  5],\n",
            "        [ 5,  7,  1,  ...,  1,  7, 10],\n",
            "        [10,  3,  2,  ...,  7, 10,  2]])\n"
          ]
        }
      ],
      "source": [
        "print(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 345,
      "metadata": {
        "id": "W8RSqbmOckWA"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "bs = 128\n",
        "data = TensorDataset(X_train, Y_train)\n",
        "dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 346,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([20, 100, 5])"
            ]
          },
          "execution_count": 346,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# indxs = [[word_to_ix[stemmer.stem(word)] for word in word_tokenize(text)] for text in train_tokens]\n",
        "emb = nn.Embedding(len(word_to_ix), 5)\n",
        "indx = torch.randint(low=0, high=len(word_to_ix), size=(20,100))\n",
        "emb(indx).size()\n",
        "# t_indx = torch.tensor(train_tokens[0])\n",
        "# t_indx.size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 347,
      "metadata": {
        "id": "M5lgGR7Dcl0X"
      },
      "outputs": [],
      "source": [
        "class BiLSTMPOSTagger(nn.Module):\n",
        "\tdef __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, n_layers, bidirectional, dropout, pad_idx):\n",
        "\t\tsuper().__init__()\n",
        "\t\tself.hidden_dim = hidden_dim\n",
        "\t\tself.input_size = input_dim\n",
        "\t\tself.output_size = embedding_dim\n",
        "\t\t# padding_idx=pad_idx - это номер id \"заполнителя\". \n",
        "\t\tself.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "\t\tself.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, bidirectional=bidirectional, dropout=dropout if n_layers > 1 else 0)\n",
        "\t\tself.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "\t\tself.dropout = nn.Dropout(dropout)\n",
        "\n",
        "\n",
        "\tdef forward(self, text):\n",
        "\n",
        "\t\tembeds = self.embedding(text)\n",
        "\t\tlstm_out, _ = self.lstm(embeds.view(len(text), text.shape[1], -1))\n",
        "\t\tpredictions = self.fc(self.dropout(lstm_out))\n",
        "\t\treturn predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 348,
      "metadata": {
        "id": "XHtLZSe8dBWV"
      },
      "outputs": [],
      "source": [
        "def train_on_epoch(model, dataloader, optimizer):\n",
        "    model.train()\n",
        "    for batch in dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input, b_tags = batch\n",
        "        \n",
        "        model.zero_grad()\n",
        "        outputs = model(b_input)  \n",
        "\n",
        "        # outputs = [batch size, sent len, out dim]\n",
        "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
        "        # outputs = [batch size * sent len, out dim]\n",
        "\n",
        "        # b_tags = [batch size, sent len]\n",
        "        b_tags = b_tags.view(-1)\n",
        "        # b_tags = [batch size * sent len]\n",
        "        \n",
        "        loss = criterion(outputs, b_tags)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def predict_on_dataloader(model, dataloaded):\n",
        "    model.eval()\n",
        "        \n",
        "    all_outputs = []\n",
        "    all_tags = []\n",
        "    for batch in dataloaded:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input, b_tags = batch\n",
        "        outputs = model(b_input)  \n",
        "        \n",
        "        outputs = outputs.view(-1, outputs.shape[-1])       \n",
        "        b_tags = b_tags.view(-1)\n",
        "\n",
        "        all_outputs.append(outputs)\n",
        "        all_tags.append(b_tags)\n",
        "\n",
        "    all_outputs = torch.cat(all_outputs)\n",
        "    all_tags = torch.cat(all_tags)\n",
        "    \n",
        "    return all_outputs, all_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 349,
      "metadata": {
        "id": "W9HPx3ywdDUj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 350,
      "metadata": {
        "id": "8uDf2IvsdEeg"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = len(word_to_ix)+1\n",
        "EMBEDDING_DIM = 100\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = len(tag2num)\n",
        "N_LAYERS = 2\n",
        "BIDIRECTIONAL = True\n",
        "DROPOUT = 0.25\n",
        "PAD_IDX = len(word_to_ix)\n",
        "\n",
        "model = BiLSTMPOSTagger(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, N_LAYERS, BIDIRECTIONAL, DROPOUT, PAD_IDX)\n",
        "model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_inds)\n",
        "optimizer = optim.Adam(model.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 351,
      "metadata": {
        "id": "AWu61Ea-dKbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0:\tLoss 6.682779793120621e-06, accuracy: 0.6406821774079473, f1-macro: 0.47165194232911767\n",
            "1:\tLoss 4.91235794582306e-06, accuracy: 0.7263602649495378, f1-macro: 0.6301597352169447\n",
            "2:\tLoss 4.006697779542802e-06, accuracy: 0.7743254795598935, f1-macro: 0.6894808246574662\n",
            "3:\tLoss 3.4446060777372553e-06, accuracy: 0.8052485593215127, f1-macro: 0.72857284013166\n",
            "4:\tLoss 3.0551556698583006e-06, accuracy: 0.8293387946887089, f1-macro: 0.7563508860095927\n",
            "5:\tLoss 2.7569475068786014e-06, accuracy: 0.8458889155396471, f1-macro: 0.7737881806646648\n",
            "6:\tLoss 2.5180677714019063e-06, accuracy: 0.859037989630805, f1-macro: 0.7904397007709923\n",
            "7:\tLoss 2.329956477326687e-06, accuracy: 0.8690074232611917, f1-macro: 0.806446949182062\n",
            "8:\tLoss 2.1651282648002452e-06, accuracy: 0.8769903503754681, f1-macro: 0.8189164148272169\n",
            "9:\tLoss 2.017388681972826e-06, accuracy: 0.8844751133169738, f1-macro: 0.8299153647234035\n",
            "10:\tLoss 1.8670394232832693e-06, accuracy: 0.8919721766084245, f1-macro: 0.8437165271754408\n",
            "11:\tLoss 1.745523252119841e-06, accuracy: 0.8986635669784805, f1-macro: 0.8520973341338246\n",
            "12:\tLoss 1.6238368050134488e-06, accuracy: 0.9052504043740044, f1-macro: 0.8642210548165047\n",
            "13:\tLoss 1.5179138045408132e-06, accuracy: 0.9116834873952164, f1-macro: 0.8746274721269198\n",
            "14:\tLoss 1.4133445802950178e-06, accuracy: 0.9171325424208319, f1-macro: 0.8834196524524202\n",
            "15:\tLoss 1.308266361115302e-06, accuracy: 0.9237316801663007, f1-macro: 0.8926155387346569\n",
            "16:\tLoss 1.2154883335184167e-06, accuracy: 0.9293529400911456, f1-macro: 0.8998200721004682\n",
            "17:\tLoss 1.1138141668820092e-06, accuracy: 0.9353001592895318, f1-macro: 0.9091936305237766\n",
            "18:\tLoss 1.0278874090483473e-06, accuracy: 0.9407676648400647, f1-macro: 0.9185753700451254\n",
            "19:\tLoss 9.395678068278187e-07, accuracy: 0.9461429177660104, f1-macro: 0.9260850154745889\n",
            "20:\tLoss 8.659538875522988e-07, accuracy: 0.9501220809732037, f1-macro: 0.931568319258425\n",
            "21:\tLoss 7.919559767799971e-07, accuracy: 0.9544272034539383, f1-macro: 0.9379400866377705\n",
            "22:\tLoss 7.203142983174823e-07, accuracy: 0.9597040535803244, f1-macro: 0.9452288722044699\n",
            "23:\tLoss 6.502499634461034e-07, accuracy: 0.9635048617133157, f1-macro: 0.9505633608435531\n",
            "24:\tLoss 5.898936942647806e-07, accuracy: 0.9673733217710044, f1-macro: 0.9562860996125517\n",
            "25:\tLoss 5.116094669540592e-07, accuracy: 0.972656322072363, f1-macro: 0.9625401718616876\n",
            "26:\tLoss 4.713085970969542e-07, accuracy: 0.9745259752639963, f1-macro: 0.9654582414341164\n",
            "27:\tLoss 3.975776474774271e-07, accuracy: 0.9792431594678869, f1-macro: 0.9699690046646332\n",
            "28:\tLoss 3.58739450719728e-07, accuracy: 0.9815556252575386, f1-macro: 0.9742809914418487\n",
            "29:\tLoss 3.1231345826521096e-07, accuracy: 0.9844216067947134, f1-macro: 0.977432863533254\n",
            "30:\tLoss 2.7818813852845454e-07, accuracy: 0.9861498059619797, f1-macro: 0.981029456310574\n",
            "31:\tLoss 2.391354701477618e-07, accuracy: 0.9882962170273745, f1-macro: 0.9831202721559962\n",
            "32:\tLoss 2.128562468318519e-07, accuracy: 0.9895816035966223, f1-macro: 0.9856430661464335\n",
            "33:\tLoss 1.9808948266187784e-07, accuracy: 0.990633283516916, f1-macro: 0.9878731089087689\n",
            "34:\tLoss 1.7701451259790566e-07, accuracy: 0.9915127585379804, f1-macro: 0.9877895996468969\n",
            "35:\tLoss 1.4709977647041562e-07, accuracy: 0.993320909979889, f1-macro: 0.9911747687164731\n",
            "36:\tLoss 1.236163709567152e-07, accuracy: 0.994557095149357, f1-macro: 0.9924617868315473\n",
            "37:\tLoss 1.223543884012269e-07, accuracy: 0.9946124467241093, f1-macro: 0.9929555007786199\n",
            "38:\tLoss 1.0397726790317313e-07, accuracy: 0.995522672620036, f1-macro: 0.9936460852856046\n",
            "39:\tLoss 9.572146790575596e-08, accuracy: 0.9957625294439627, f1-macro: 0.9939370657438346\n",
            "40:\tLoss 6.864778199172372e-08, accuracy: 0.9972324212623849, f1-macro: 0.9963007950483792\n",
            "41:\tLoss 6.998838428594748e-08, accuracy: 0.9970848170630454, f1-macro: 0.9963654761630356\n",
            "42:\tLoss 6.196176489367993e-08, accuracy: 0.9975153293111189, f1-macro: 0.9967891505334397\n",
            "43:\tLoss 4.539006312713119e-08, accuracy: 0.9983517531073759, f1-macro: 0.997765536559497\n",
            "44:\tLoss 4.043635516236865e-08, accuracy: 0.9985485587064952, f1-macro: 0.9976125976623491\n",
            "45:\tLoss 3.172755230854897e-08, accuracy: 0.9990098218294311, f1-macro: 0.9987628839460703\n",
            "46:\tLoss 3.106599464323657e-08, accuracy: 0.9989852211295411, f1-macro: 0.9987916767689441\n",
            "47:\tLoss 2.9067471834661862e-08, accuracy: 0.9989913713045137, f1-macro: 0.9988234365273456\n",
            "48:\tLoss 2.5498049206339764e-08, accuracy: 0.9992250779534678, f1-macro: 0.9991905379360475\n",
            "49:\tLoss 2.3589527268721672e-08, accuracy: 0.9992927298781651, f1-macro: 0.9992558798785339\n"
          ]
        }
      ],
      "source": [
        "epochs = 50\n",
        "for e in range(epochs):\n",
        "    train_on_epoch(model, dataloader, optimizer)    \n",
        "    \n",
        "    all_outputs, all_tags = predict_on_dataloader(model, dataloader)\n",
        "    loss = criterion(all_outputs, all_tags).item()\n",
        "    all_outputs = all_outputs.detach().cpu().numpy()\n",
        "    all_tags = all_tags.detach().cpu().numpy()\n",
        "    \n",
        "    mask = all_tags != pad_inds\n",
        "    loss = loss/len(all_tags[mask]) \n",
        "    all_tags = all_tags[mask]\n",
        "    all_preds = np.argmax(all_outputs, axis=1)[mask]\n",
        "    \n",
        "    print(f\"{e}:\\tLoss {loss}, \"\n",
        "          f\"accuracy: {accuracy_score(all_tags, all_preds)}, \"\n",
        "          f\"f1-macro: {f1_score(all_tags, all_preds, average='macro')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 352,
      "metadata": {
        "id": "8kcXubKVdVov"
      },
      "outputs": [],
      "source": [
        "def count_metrics(model, dataloader):\n",
        "  y_pred, y_true = predict_on_dataloader(model, dataloader)\n",
        "\n",
        "  y_pred = y_pred.detach().cpu().numpy()\n",
        "  y_true = y_true.detach().cpu().numpy()\n",
        "\n",
        "  mask = y_true != pad_inds\n",
        "  y_true = y_true[mask]\n",
        "  y_pred = np.argmax(y_pred, axis=1)[mask]\n",
        "\n",
        "  print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 353,
      "metadata": {
        "id": "25kR8EZsdavw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      9962\n",
            "           1       1.00      1.00      1.00     13578\n",
            "           2       1.00      1.00      1.00      8547\n",
            "           3       0.99      1.00      1.00     10404\n",
            "           4       1.00      1.00      1.00      5202\n",
            "           5       1.00      1.00      1.00     13014\n",
            "           6       1.00      1.00      1.00       649\n",
            "           7       1.00      1.00      1.00     27080\n",
            "           8       1.00      1.00      1.00      3339\n",
            "           9       1.00      1.00      1.00      4484\n",
            "          10       1.00      1.00      1.00     15619\n",
            "          11       1.00      1.00      1.00     10523\n",
            "          12       1.00      1.00      1.00     16990\n",
            "          13       1.00      1.00      1.00      3134\n",
            "          14       1.00      1.00      1.00       484\n",
            "          15       1.00      1.00      1.00     18849\n",
            "          16       1.00      1.00      1.00       739\n",
            "\n",
            "    accuracy                           1.00    162597\n",
            "   macro avg       1.00      1.00      1.00    162597\n",
            "weighted avg       1.00      1.00      1.00    162597\n",
            "\n"
          ]
        }
      ],
      "source": [
        "count_metrics(model, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 354,
      "metadata": {
        "id": "VAOUiigWdY7m"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.74      0.71      1466\n",
            "           1       0.84      0.84      0.84      1656\n",
            "           2       0.81      0.77      0.79      1066\n",
            "           3       0.84      0.90      0.87      1336\n",
            "           4       0.99      0.99      0.99       599\n",
            "           5       0.95      0.96      0.96      1607\n",
            "           6       0.81      0.69      0.74       115\n",
            "           7       0.68      0.81      0.74      3446\n",
            "           8       0.89      0.52      0.66       448\n",
            "           9       0.69      0.76      0.73       546\n",
            "          10       0.95      0.95      0.95      1923\n",
            "          11       0.78      0.45      0.57      1773\n",
            "          12       0.99      0.99      0.99      2467\n",
            "          13       0.55      0.56      0.56       330\n",
            "          14       0.80      0.68      0.73        81\n",
            "          15       0.77      0.73      0.75      2306\n",
            "          16       0.12      0.32      0.18       114\n",
            "\n",
            "    accuracy                           0.81     21279\n",
            "   macro avg       0.77      0.74      0.75     21279\n",
            "weighted avg       0.82      0.81      0.81     21279\n",
            "\n"
          ]
        }
      ],
      "source": [
        "data = TensorDataset(X_test, Y_test)\n",
        "test_dataloader = DataLoader(data, sampler=SequentialSampler(data), batch_size=bs)\n",
        "count_metrics(model, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W32kZg1qdbSj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
